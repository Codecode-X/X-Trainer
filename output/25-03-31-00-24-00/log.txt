
=======配置信息=======
DATALOADER:
  BATCH_SIZE_TEST: 100
  BATCH_SIZE_TRAIN: 32
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
DATASET:
  DATASET_DIR: /root/autodl-tmp/caltech-101
  IMAGE_DIR: /root/autodl-tmp/caltech-101/101_ObjectCategories
  NAME: Caltech101
  NUM_SHOTS: -1
  SPLIT: [0.7, 0.1, 0.2]
EVALUATOR:
  NAME: EvaluatorClassification
  calc_cmat: True
  per_class: True
INPUT:
  AFTER_TOTENSOR_TRANSFORMS: []
  BEFORE_TOTENSOR_TRANSFORMS: ['StandardNoAugTransform']
  INTERPOLATION: BICUBIC
  NORMALIZE: True
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  SIZE: 224
  StandardNoAugTransform: None
LR_SCHEDULER:
  NAME: CosineLrScheduler
  WARMUP:
    CONS_LR: 1e-5
    EPOCHS: 1
    NAME: ConstantWarmupScheduler
    WARMUP_RECOUNT: True
MODEL:
  NAME: CoOpClip
  download_root: ~/.cache/clip
  init_ctx: a photo of a
  pretrained: ViT-B/16
OPTIMIZER:
  LR: 0.002
  NAME: SGD
  dampening: 0.0
  momentum: 0.9
  nesterov: False
  weight_decay: 0.0005
OUTPUT_DIR: ./output/25-03-31-00-24-00
RESUME: 
SAMPLER:
  TEST_SP: SequentialSampler
  TRAIN_SP: RandomSampler
SEED: 42
TEST:
  FINAL_MODEL: best_val
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  DO_EVAL: True
  MAX_EPOCH: 50
  NO_TEST: False
  PRINT_FREQ: 5
TRAINER:
  FROZEN: False
  NAME: TrainerCoOpCLIP
  PREC: fp32
USE_CUDA: True
VERBOSE: True
=======配置信息=======

设置固定种子：42
Loading trainer: TrainerCoOpCLIP
构建数据加载器...
Loading dataset: Caltech101
Reading split from /root/autodl-tmp/caltech-101/split.json
构建训练数据增强.....
ToTensor 前训练数据增强：StandardNoAugTransform
构建测试数据增强.....
测试数据增强：
  - 标准标准图像预处理转换: resize + RGB + toTensor + normalize
Loading sampler: RandomSampler
Loading sampler: SequentialSampler
Loading sampler: SequentialSampler
--------------  ----------
数据集          Caltech101
类别数量        100
有标签训练数据  5,763
验证数据        824
测试数据        1,655
--------------  ----------
构建模型，优化器，学习率调度器...
Loading model: CoOpClip
正在调用模型构造方法构造模型....
模型参数数量： 149620737
从小到大排序后的数据集文本标签： ['face', 'leopard', 'motorbike', 'accordion', 'airplane', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
正在初始化 PromptLearner...
初始上下文向量："a photo of a"
上下文 token 数为 (tokens): 4
Loading optimizer: SGD
Loading lr_scheduler: CosineLrScheduler
Loading warmup: ConstantWarmupScheduler
Adjusting learning rate of group 0 to 1.0000e-05.
构建评估器...
Loading evaluator: EvaluatorClassification
Initialize tensorboard (log_dir=./output/25-03-31-00-24-00/tensorboard)
epoch [1/50] batch [5/180] time 0.237 (0.573) data 0.000 (0.261) loss 25.0013 (20.6651) acc 84.3750 (88.1250) lr 1.0000e-05 eta 1:25:49
epoch [1/50] batch [10/180] time 0.238 (0.405) data 0.000 (0.131) loss 21.9270 (20.0710) acc 87.5000 (89.3750) lr 1.0000e-05 eta 1:00:38
epoch [1/50] batch [15/180] time 0.237 (0.349) data 0.000 (0.087) loss 0.7670 (17.6005) acc 93.7500 (89.7917) lr 1.0000e-05 eta 0:52:14
epoch [1/50] batch [20/180] time 0.237 (0.321) data 0.000 (0.065) loss 11.5781 (15.4423) acc 81.2500 (90.0000) lr 1.0000e-05 eta 0:48:00
epoch [1/50] batch [25/180] time 0.238 (0.304) data 0.000 (0.052) loss 5.4729 (13.2643) acc 93.7500 (90.3750) lr 1.0000e-05 eta 0:45:28
epoch [1/50] batch [30/180] time 0.236 (0.293) data 0.000 (0.044) loss 1.0383 (12.4013) acc 93.7500 (90.3125) lr 1.0000e-05 eta 0:43:46
epoch [1/50] batch [35/180] time 0.237 (0.285) data 0.000 (0.037) loss 1.0173 (10.9642) acc 96.8750 (91.0714) lr 1.0000e-05 eta 0:42:32
epoch [1/50] batch [40/180] time 0.237 (0.279) data 0.000 (0.033) loss 0.0010 (10.0647) acc 100.0000 (91.1719) lr 1.0000e-05 eta 0:41:37
epoch [1/50] batch [45/180] time 0.237 (0.274) data 0.000 (0.029) loss 2.6312 (9.4565) acc 90.6250 (91.4583) lr 1.0000e-05 eta 0:40:54
epoch [1/50] batch [50/180] time 0.237 (0.270) data 0.000 (0.026) loss 13.3385 (9.0249) acc 84.3750 (91.5625) lr 1.0000e-05 eta 0:40:19
epoch [1/50] batch [55/180] time 0.237 (0.267) data 0.000 (0.024) loss 0.8548 (8.7394) acc 93.7500 (91.4205) lr 1.0000e-05 eta 0:39:51
epoch [1/50] batch [60/180] time 0.237 (0.265) data 0.000 (0.022) loss 0.0490 (8.0551) acc 96.8750 (91.9271) lr 1.0000e-05 eta 0:39:26
epoch [1/50] batch [65/180] time 0.237 (0.263) data 0.000 (0.020) loss 0.1671 (7.7594) acc 96.8750 (91.9712) lr 1.0000e-05 eta 0:39:06
epoch [1/50] batch [70/180] time 0.237 (0.261) data 0.000 (0.019) loss 0.7968 (7.6986) acc 96.8750 (92.0536) lr 1.0000e-05 eta 0:38:48
epoch [1/50] batch [75/180] time 0.237 (0.259) data 0.000 (0.018) loss 1.1482 (7.4880) acc 96.8750 (92.3750) lr 1.0000e-05 eta 0:38:33
epoch [1/50] batch [80/180] time 0.237 (0.258) data 0.000 (0.016) loss 2.9100 (7.4289) acc 87.5000 (92.2656) lr 1.0000e-05 eta 0:38:19
epoch [1/50] batch [85/180] time 0.237 (0.257) data 0.000 (0.016) loss 0.0000 (7.1919) acc 100.0000 (92.3897) lr 1.0000e-05 eta 0:38:07
epoch [1/50] batch [90/180] time 0.237 (0.256) data 0.000 (0.015) loss 2.1397 (7.0891) acc 87.5000 (92.0833) lr 1.0000e-05 eta 0:37:56
epoch [1/50] batch [95/180] time 0.238 (0.255) data 0.000 (0.014) loss 3.6295 (7.2175) acc 93.7500 (91.9408) lr 1.0000e-05 eta 0:37:46
epoch [1/50] batch [100/180] time 0.237 (0.254) data 0.000 (0.013) loss 3.9819 (7.0098) acc 87.5000 (92.0938) lr 1.0000e-05 eta 0:37:37
epoch [1/50] batch [105/180] time 0.237 (0.253) data 0.000 (0.013) loss 0.8427 (6.8463) acc 93.7500 (92.1131) lr 1.0000e-05 eta 0:37:29
epoch [1/50] batch [110/180] time 0.237 (0.252) data 0.000 (0.012) loss 9.9299 (6.7984) acc 87.5000 (92.0170) lr 1.0000e-05 eta 0:37:21
epoch [1/50] batch [115/180] time 0.237 (0.251) data 0.000 (0.012) loss 3.9250 (6.6942) acc 96.8750 (92.1196) lr 1.0000e-05 eta 0:37:14
epoch [1/50] batch [120/180] time 0.237 (0.251) data 0.000 (0.011) loss 0.0000 (6.5744) acc 100.0000 (92.2917) lr 1.0000e-05 eta 0:37:07
epoch [1/50] batch [125/180] time 0.237 (0.250) data 0.000 (0.011) loss 2.8732 (6.4006) acc 96.8750 (92.3750) lr 1.0000e-05 eta 0:37:01
epoch [1/50] batch [130/180] time 0.237 (0.250) data 0.000 (0.010) loss 4.4643 (6.2695) acc 93.7500 (92.3558) lr 1.0000e-05 eta 0:36:55
epoch [1/50] batch [135/180] time 0.237 (0.249) data 0.000 (0.010) loss 2.4751 (6.2063) acc 90.6250 (92.3843) lr 1.0000e-05 eta 0:36:49
epoch [1/50] batch [140/180] time 0.237 (0.249) data 0.000 (0.009) loss 0.0125 (6.0181) acc 100.0000 (92.5223) lr 1.0000e-05 eta 0:36:44
epoch [1/50] batch [145/180] time 0.237 (0.248) data 0.000 (0.009) loss 1.3204 (5.8435) acc 96.8750 (92.6078) lr 1.0000e-05 eta 0:36:39
epoch [1/50] batch [150/180] time 0.237 (0.248) data 0.000 (0.009) loss 5.9303 (5.7349) acc 93.7500 (92.7083) lr 1.0000e-05 eta 0:36:35
epoch [1/50] batch [155/180] time 0.237 (0.248) data 0.000 (0.009) loss 2.6210 (5.5999) acc 84.3750 (92.7823) lr 1.0000e-05 eta 0:36:30
epoch [1/50] batch [160/180] time 0.237 (0.247) data 0.000 (0.008) loss 6.2172 (5.5183) acc 93.7500 (92.8516) lr 1.0000e-05 eta 0:36:26
epoch [1/50] batch [165/180] time 0.238 (0.247) data 0.000 (0.008) loss 5.7575 (5.4851) acc 93.7500 (92.8598) lr 1.0000e-05 eta 0:36:22
epoch [1/50] batch [170/180] time 0.237 (0.247) data 0.000 (0.008) loss 0.8978 (5.3995) acc 93.7500 (92.8309) lr 1.0000e-05 eta 0:36:18
epoch [1/50] batch [175/180] time 0.236 (0.246) data 0.000 (0.008) loss 5.0599 (5.3071) acc 90.6250 (92.9107) lr 1.0000e-05 eta 0:36:15
Adjusting learning rate of group 0 to 2.0000e-03.
epoch [1/50] batch [180/180] time 0.237 (0.246) data 0.000 (0.007) loss 0.0189 (5.2635) acc 100.0000 (92.8819) lr 2.0000e-03 eta 0:36:11
在 *val* 集上测试
=> result
* total: 824
* correct: 785
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 92.7%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 20	acc: 100.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 2	acc: 50.0%
* class: 6 (ant)	total: 4	correct: 4	acc: 100.0%
* class: 7 (barrel)	total: 5	correct: 4	acc: 80.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 1	acc: 33.3%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 6	acc: 100.0%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 4	acc: 80.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 3	acc: 42.9%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 6	acc: 100.0%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 6	acc: 100.0%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 6	acc: 100.0%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 7	acc: 100.0%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 3	acc: 100.0%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 5	acc: 100.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 10	acc: 90.9%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 4	acc: 100.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 4	acc: 100.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 3	acc: 100.0%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 7	acc: 87.5%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 3	acc: 75.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 92.9%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model-best.pth.tar
epoch [2/50] batch [5/180] time 0.237 (0.355) data 0.000 (0.118) loss 17.7194 (11.7812) acc 87.5000 (88.7500) lr 2.0000e-03 eta 0:52:11
epoch [2/50] batch [10/180] time 0.240 (0.297) data 0.000 (0.059) loss 6.9975 (8.5942) acc 90.6250 (91.2500) lr 2.0000e-03 eta 0:43:34
epoch [2/50] batch [15/180] time 0.237 (0.277) data 0.000 (0.039) loss 4.9559 (9.5432) acc 90.6250 (89.3750) lr 2.0000e-03 eta 0:40:37
epoch [2/50] batch [20/180] time 0.237 (0.267) data 0.000 (0.030) loss 6.3968 (8.6266) acc 87.5000 (89.6875) lr 2.0000e-03 eta 0:39:08
epoch [2/50] batch [25/180] time 0.237 (0.261) data 0.000 (0.024) loss 5.9460 (7.5386) acc 84.3750 (90.0000) lr 2.0000e-03 eta 0:38:14
epoch [2/50] batch [30/180] time 0.237 (0.257) data 0.000 (0.020) loss 0.2974 (7.7482) acc 96.8750 (90.1042) lr 2.0000e-03 eta 0:37:37
epoch [2/50] batch [35/180] time 0.237 (0.254) data 0.000 (0.017) loss 0.3959 (7.1053) acc 96.8750 (90.3571) lr 2.0000e-03 eta 0:37:11
epoch [2/50] batch [40/180] time 0.237 (0.252) data 0.000 (0.015) loss 1.2257 (6.7930) acc 90.6250 (90.6250) lr 2.0000e-03 eta 0:36:51
epoch [2/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.5406 (6.2469) acc 93.7500 (90.9028) lr 2.0000e-03 eta 0:36:36
epoch [2/50] batch [50/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.0000 (5.8934) acc 100.0000 (91.5000) lr 2.0000e-03 eta 0:36:23
epoch [2/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.5287 (5.7346) acc 96.8750 (91.6477) lr 2.0000e-03 eta 0:36:12
epoch [2/50] batch [60/180] time 0.238 (0.247) data 0.000 (0.010) loss 1.2504 (5.6336) acc 93.7500 (91.5625) lr 2.0000e-03 eta 0:36:04
epoch [2/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 11.5843 (5.8388) acc 90.6250 (91.5385) lr 2.0000e-03 eta 0:35:56
epoch [2/50] batch [70/180] time 0.237 (0.246) data 0.000 (0.009) loss 4.5834 (5.6571) acc 96.8750 (91.7857) lr 2.0000e-03 eta 0:35:49
epoch [2/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.008) loss 1.7916 (5.4610) acc 96.8750 (91.9583) lr 2.0000e-03 eta 0:35:42
epoch [2/50] batch [80/180] time 0.237 (0.245) data 0.000 (0.007) loss 2.0220 (5.5148) acc 96.8750 (91.7969) lr 2.0000e-03 eta 0:35:37
epoch [2/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.2882 (5.4477) acc 96.8750 (91.8015) lr 2.0000e-03 eta 0:35:32
epoch [2/50] batch [90/180] time 0.237 (0.244) data 0.000 (0.007) loss 4.7826 (5.2907) acc 90.6250 (91.8056) lr 2.0000e-03 eta 0:35:27
epoch [2/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 2.7503 (5.2288) acc 90.6250 (91.7763) lr 2.0000e-03 eta 0:35:23
epoch [2/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.006) loss 2.9335 (5.0918) acc 90.6250 (91.8125) lr 2.0000e-03 eta 0:35:19
epoch [2/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0015 (4.9745) acc 100.0000 (91.9345) lr 2.0000e-03 eta 0:35:15
epoch [2/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 2.6235 (4.8446) acc 93.7500 (92.0739) lr 2.0000e-03 eta 0:35:12
epoch [2/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 1.5064 (4.6779) acc 93.7500 (92.2011) lr 2.0000e-03 eta 0:35:08
epoch [2/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0006 (4.5691) acc 100.0000 (92.2396) lr 2.0000e-03 eta 0:35:05
epoch [2/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 1.2539 (4.4700) acc 93.7500 (92.3250) lr 2.0000e-03 eta 0:35:03
epoch [2/50] batch [130/180] time 0.238 (0.242) data 0.000 (0.005) loss 2.6265 (4.3560) acc 93.7500 (92.4760) lr 2.0000e-03 eta 0:35:00
epoch [2/50] batch [135/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.1128 (4.2322) acc 96.8750 (92.5926) lr 2.0000e-03 eta 0:34:57
epoch [2/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.5325 (4.1697) acc 93.7500 (92.6339) lr 2.0000e-03 eta 0:34:55
epoch [2/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 3.4915 (4.1173) acc 93.7500 (92.7371) lr 2.0000e-03 eta 0:34:52
epoch [2/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 5.6567 (4.0813) acc 87.5000 (92.7500) lr 2.0000e-03 eta 0:34:50
epoch [2/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.8952 (4.0526) acc 93.7500 (92.6815) lr 2.0000e-03 eta 0:34:47
epoch [2/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.0227 (3.9803) acc 96.8750 (92.7539) lr 2.0000e-03 eta 0:34:45
epoch [2/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.004) loss 3.0709 (3.9535) acc 90.6250 (92.7273) lr 2.0000e-03 eta 0:34:43
epoch [2/50] batch [170/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4722 (3.8789) acc 96.8750 (92.7574) lr 2.0000e-03 eta 0:34:41
epoch [2/50] batch [175/180] time 0.236 (0.240) data 0.000 (0.003) loss 1.2012 (3.8197) acc 93.7500 (92.8214) lr 2.0000e-03 eta 0:34:38
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [2/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 3.7745 (3.8466) acc 93.7500 (92.8125) lr 1.9980e-03 eta 0:34:36
在 *val* 集上测试
=> result
* total: 824
* correct: 761
* accuracy: 92.4%
* error: 7.6%
* macro_f1: 88.4%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 20	acc: 100.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 1	acc: 25.0%
* class: 6 (ant)	total: 4	correct: 4	acc: 100.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 1	acc: 33.3%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 9	acc: 100.0%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 2	acc: 33.3%
* class: 22 (chandelier)	total: 11	correct: 9	acc: 81.8%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 6	acc: 100.0%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 6	acc: 85.7%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 5	acc: 100.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 3	acc: 27.3%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 7	acc: 87.5%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.0%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [3/50] batch [5/180] time 0.237 (0.331) data 0.000 (0.091) loss 0.3100 (1.0301) acc 93.7500 (93.1250) lr 1.9980e-03 eta 0:47:35
epoch [3/50] batch [10/180] time 0.237 (0.284) data 0.000 (0.045) loss 4.7734 (2.9654) acc 90.6250 (93.4375) lr 1.9980e-03 eta 0:40:49
epoch [3/50] batch [15/180] time 0.237 (0.268) data 0.000 (0.030) loss 7.2618 (3.1243) acc 87.5000 (93.3333) lr 1.9980e-03 eta 0:38:33
epoch [3/50] batch [20/180] time 0.237 (0.260) data 0.000 (0.023) loss 0.0002 (2.5971) acc 100.0000 (93.2812) lr 1.9980e-03 eta 0:37:25
epoch [3/50] batch [25/180] time 0.237 (0.256) data 0.000 (0.018) loss 0.3517 (2.5517) acc 93.7500 (93.1250) lr 1.9980e-03 eta 0:36:43
epoch [3/50] batch [30/180] time 0.237 (0.253) data 0.000 (0.015) loss 1.3710 (2.4101) acc 90.6250 (92.9167) lr 1.9980e-03 eta 0:36:15
epoch [3/50] batch [35/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.2112 (2.1585) acc 96.8750 (93.2143) lr 1.9980e-03 eta 0:35:54
epoch [3/50] batch [40/180] time 0.237 (0.249) data 0.000 (0.011) loss 1.6703 (2.0818) acc 90.6250 (92.9688) lr 1.9980e-03 eta 0:35:41
epoch [3/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.010) loss 1.4497 (1.9865) acc 93.7500 (92.9861) lr 1.9980e-03 eta 0:35:28
epoch [3/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.009) loss 1.0209 (1.9520) acc 96.8750 (93.1875) lr 1.9980e-03 eta 0:35:18
epoch [3/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.008) loss 3.6367 (2.0713) acc 90.6250 (93.0114) lr 1.9980e-03 eta 0:35:09
epoch [3/50] batch [60/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.3465 (2.0141) acc 96.8750 (93.2292) lr 1.9980e-03 eta 0:35:02
epoch [3/50] batch [65/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.1167 (2.0055) acc 96.8750 (93.2212) lr 1.9980e-03 eta 0:34:55
epoch [3/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 2.2802 (2.0024) acc 90.6250 (92.9911) lr 1.9980e-03 eta 0:34:49
epoch [3/50] batch [75/180] time 0.237 (0.243) data 0.000 (0.006) loss 7.0960 (2.0184) acc 84.3750 (92.9583) lr 1.9980e-03 eta 0:34:44
epoch [3/50] batch [80/180] time 0.237 (0.243) data 0.000 (0.006) loss 1.5775 (1.9428) acc 93.7500 (93.0859) lr 1.9980e-03 eta 0:34:40
epoch [3/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0006 (1.9241) acc 100.0000 (93.1250) lr 1.9980e-03 eta 0:34:35
epoch [3/50] batch [90/180] time 0.237 (0.242) data 0.000 (0.005) loss 1.3838 (1.8999) acc 90.6250 (93.0556) lr 1.9980e-03 eta 0:34:31
epoch [3/50] batch [95/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1633 (1.8501) acc 96.8750 (93.2237) lr 1.9980e-03 eta 0:34:28
epoch [3/50] batch [100/180] time 0.237 (0.242) data 0.000 (0.005) loss 2.1741 (1.8300) acc 93.7500 (93.1875) lr 1.9980e-03 eta 0:34:25
epoch [3/50] batch [105/180] time 0.238 (0.242) data 0.001 (0.004) loss 0.0000 (1.7959) acc 100.0000 (93.2738) lr 1.9980e-03 eta 0:34:21
epoch [3/50] batch [110/180] time 0.238 (0.241) data 0.000 (0.004) loss 2.8691 (1.7668) acc 93.7500 (93.2955) lr 1.9980e-03 eta 0:34:19
epoch [3/50] batch [115/180] time 0.237 (0.241) data 0.000 (0.004) loss 3.4700 (1.7763) acc 87.5000 (93.2880) lr 1.9980e-03 eta 0:34:16
epoch [3/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.1942 (1.7609) acc 96.8750 (93.3594) lr 1.9980e-03 eta 0:34:13
epoch [3/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.8814 (1.7387) acc 93.7500 (93.3500) lr 1.9980e-03 eta 0:34:11
epoch [3/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.2714 (1.7355) acc 87.5000 (93.2933) lr 1.9980e-03 eta 0:34:08
epoch [3/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.7941 (1.6936) acc 87.5000 (93.2407) lr 1.9980e-03 eta 0:34:06
epoch [3/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.003) loss 1.5372 (1.6608) acc 87.5000 (93.2143) lr 1.9980e-03 eta 0:34:04
epoch [3/50] batch [145/180] time 0.237 (0.240) data 0.000 (0.003) loss 4.2795 (1.7019) acc 84.3750 (92.9741) lr 1.9980e-03 eta 0:34:02
epoch [3/50] batch [150/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.5944 (1.6681) acc 90.6250 (92.9583) lr 1.9980e-03 eta 0:33:59
epoch [3/50] batch [155/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0209 (1.6347) acc 100.0000 (92.9435) lr 1.9980e-03 eta 0:33:57
epoch [3/50] batch [160/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.6554 (1.6298) acc 93.7500 (92.9492) lr 1.9980e-03 eta 0:33:55
epoch [3/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.6169 (1.6178) acc 96.8750 (92.9924) lr 1.9980e-03 eta 0:33:53
epoch [3/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.9756 (1.6016) acc 93.7500 (92.9963) lr 1.9980e-03 eta 0:33:51
epoch [3/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.5112 (1.5749) acc 96.8750 (92.9643) lr 1.9980e-03 eta 0:33:49
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [3/50] batch [180/180] time 0.236 (0.240) data 0.000 (0.003) loss 0.7631 (1.5641) acc 93.7500 (93.0035) lr 1.0000e-05 eta 0:33:47
在 *val* 集上测试
=> result
* total: 824
* correct: 768
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 89.7%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 1	acc: 25.0%
* class: 6 (ant)	total: 4	correct: 4	acc: 100.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 9	acc: 100.0%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 5	acc: 83.3%
* class: 22 (chandelier)	total: 11	correct: 9	acc: 81.8%
* class: 23 (cougar_body)	total: 5	correct: 4	acc: 80.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 6	acc: 85.7%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 6	acc: 85.7%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 5	acc: 100.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 7	acc: 87.5%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 2	acc: 50.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 90.2%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [4/50] batch [5/180] time 0.237 (0.348) data 0.000 (0.111) loss 0.0000 (0.6089) acc 100.0000 (96.2500) lr 1.0000e-05 eta 0:49:02
epoch [4/50] batch [10/180] time 0.237 (0.293) data 0.000 (0.056) loss 0.6432 (0.9261) acc 93.7500 (95.3125) lr 1.0000e-05 eta 0:41:11
epoch [4/50] batch [15/180] time 0.238 (0.274) data 0.000 (0.037) loss 0.5447 (0.8382) acc 93.7500 (95.4167) lr 1.0000e-05 eta 0:38:34
epoch [4/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.028) loss 0.9300 (0.7285) acc 90.6250 (95.6250) lr 1.0000e-05 eta 0:37:20
epoch [4/50] batch [25/180] time 0.237 (0.260) data 0.000 (0.022) loss 0.7552 (0.7450) acc 93.7500 (95.1250) lr 1.0000e-05 eta 0:36:31
epoch [4/50] batch [30/180] time 0.237 (0.256) data 0.000 (0.019) loss 0.6194 (0.7784) acc 93.7500 (94.8958) lr 1.0000e-05 eta 0:35:59
epoch [4/50] batch [35/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.4405 (0.7767) acc 93.7500 (94.7321) lr 1.0000e-05 eta 0:35:35
epoch [4/50] batch [40/180] time 0.238 (0.251) data 0.000 (0.014) loss 3.7353 (0.8541) acc 78.1250 (94.4531) lr 1.0000e-05 eta 0:35:17
epoch [4/50] batch [45/180] time 0.238 (0.250) data 0.000 (0.013) loss 1.5339 (0.8367) acc 87.5000 (94.5139) lr 1.0000e-05 eta 0:35:03
epoch [4/50] batch [50/180] time 0.238 (0.249) data 0.000 (0.011) loss 1.3833 (0.8238) acc 90.6250 (94.5625) lr 1.0000e-05 eta 0:34:51
epoch [4/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.010) loss 0.4059 (0.8032) acc 93.7500 (94.4318) lr 1.0000e-05 eta 0:34:41
epoch [4/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.009) loss 2.6092 (0.8709) acc 90.6250 (94.2188) lr 1.0000e-05 eta 0:34:32
epoch [4/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.0316 (0.9039) acc 96.8750 (94.2308) lr 1.0000e-05 eta 0:34:25
epoch [4/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.6052 (0.9048) acc 90.6250 (94.0625) lr 1.0000e-05 eta 0:34:18
epoch [4/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.008) loss 2.3584 (0.9239) acc 93.7500 (94.0000) lr 1.0000e-05 eta 0:34:12
epoch [4/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.7001 (0.8991) acc 96.8750 (94.1016) lr 1.0000e-05 eta 0:34:07
epoch [4/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 3.7903 (0.9414) acc 87.5000 (94.0074) lr 1.0000e-05 eta 0:34:02
epoch [4/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1773 (0.9247) acc 96.8750 (94.1667) lr 1.0000e-05 eta 0:33:58
epoch [4/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 2.8062 (0.9369) acc 90.6250 (94.1776) lr 1.0000e-05 eta 0:33:54
epoch [4/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.0000 (0.9013) acc 100.0000 (94.3750) lr 1.0000e-05 eta 0:33:50
epoch [4/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.2403 (0.9014) acc 96.8750 (94.3750) lr 1.0000e-05 eta 0:33:46
epoch [4/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 3.2400 (0.9445) acc 90.6250 (94.2614) lr 1.0000e-05 eta 0:33:43
epoch [4/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 3.0650 (0.9468) acc 90.6250 (94.2663) lr 1.0000e-05 eta 0:33:40
epoch [4/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.7412 (0.9226) acc 90.6250 (94.2708) lr 1.0000e-05 eta 0:33:37
epoch [4/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 2.4800 (0.9313) acc 90.6250 (94.1500) lr 1.0000e-05 eta 0:33:34
epoch [4/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.3726 (0.9956) acc 90.6250 (94.1106) lr 1.0000e-05 eta 0:33:31
epoch [4/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4427 (0.9721) acc 90.6250 (94.2130) lr 1.0000e-05 eta 0:33:29
epoch [4/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 2.0112 (0.9839) acc 87.5000 (94.0848) lr 1.0000e-05 eta 0:33:26
epoch [4/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.5243 (0.9685) acc 93.7500 (94.1379) lr 1.0000e-05 eta 0:33:24
epoch [4/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.2066 (0.9768) acc 93.7500 (94.0625) lr 1.0000e-05 eta 0:33:21
epoch [4/50] batch [155/180] time 0.238 (0.241) data 0.001 (0.004) loss 0.1189 (0.9590) acc 93.7500 (94.0524) lr 1.0000e-05 eta 0:33:19
epoch [4/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0028 (0.9448) acc 100.0000 (94.1211) lr 1.0000e-05 eta 0:33:17
epoch [4/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.6313 (0.9346) acc 93.7500 (94.1288) lr 1.0000e-05 eta 0:33:15
epoch [4/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1513 (0.9634) acc 96.8750 (94.0809) lr 1.0000e-05 eta 0:33:13
epoch [4/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 3.3249 (0.9786) acc 90.6250 (94.0536) lr 1.0000e-05 eta 0:33:11
Adjusting learning rate of group 0 to 1.9980e-03.
epoch [4/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.3866 (0.9749) acc 90.6250 (94.0278) lr 1.9980e-03 eta 0:33:09
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.6%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 1	acc: 25.0%
* class: 6 (ant)	total: 4	correct: 4	acc: 100.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 9	acc: 100.0%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 5	acc: 83.3%
* class: 22 (chandelier)	total: 11	correct: 9	acc: 81.8%
* class: 23 (cougar_body)	total: 5	correct: 4	acc: 80.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 6	acc: 85.7%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 5	acc: 100.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 7	acc: 87.5%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 2	acc: 50.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 90.0%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [5/50] batch [5/180] time 0.237 (0.339) data 0.000 (0.101) loss 0.2904 (0.5799) acc 96.8750 (93.7500) lr 1.9980e-03 eta 0:46:47
epoch [5/50] batch [10/180] time 0.237 (0.288) data 0.000 (0.051) loss 0.2290 (0.6331) acc 96.8750 (93.4375) lr 1.9980e-03 eta 0:39:41
epoch [5/50] batch [15/180] time 0.237 (0.271) data 0.000 (0.034) loss 1.1858 (0.7022) acc 87.5000 (93.3333) lr 1.9980e-03 eta 0:37:22
epoch [5/50] batch [20/180] time 0.236 (0.263) data 0.000 (0.025) loss 0.6449 (0.6031) acc 93.7500 (93.7500) lr 1.9980e-03 eta 0:36:09
epoch [5/50] batch [25/180] time 0.237 (0.258) data 0.000 (0.020) loss 0.6314 (0.7561) acc 96.8750 (93.3750) lr 1.9980e-03 eta 0:35:26
epoch [5/50] batch [30/180] time 0.237 (0.254) data 0.000 (0.017) loss 1.4535 (0.7783) acc 87.5000 (92.9167) lr 1.9980e-03 eta 0:34:56
epoch [5/50] batch [35/180] time 0.237 (0.252) data 0.000 (0.015) loss 0.2847 (0.8152) acc 96.8750 (92.8571) lr 1.9980e-03 eta 0:34:35
epoch [5/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.013) loss 2.2228 (0.8139) acc 84.3750 (93.0469) lr 1.9980e-03 eta 0:34:18
epoch [5/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.011) loss 1.1874 (0.8063) acc 90.6250 (92.9861) lr 1.9980e-03 eta 0:34:05
epoch [5/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.0000 (0.7772) acc 100.0000 (93.1250) lr 1.9980e-03 eta 0:33:55
epoch [5/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.5850 (0.7865) acc 96.8750 (93.4091) lr 1.9980e-03 eta 0:33:46
epoch [5/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.0740 (0.7769) acc 96.8750 (93.4896) lr 1.9980e-03 eta 0:33:39
epoch [5/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.4397 (0.7324) acc 93.7500 (93.7019) lr 1.9980e-03 eta 0:33:32
epoch [5/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.3187 (0.8215) acc 93.7500 (93.5268) lr 1.9980e-03 eta 0:33:26
epoch [5/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0567 (0.8116) acc 96.8750 (93.4167) lr 1.9980e-03 eta 0:33:21
epoch [5/50] batch [80/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.0018 (0.7817) acc 100.0000 (93.4766) lr 1.9980e-03 eta 0:33:16
epoch [5/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0127 (0.8357) acc 100.0000 (93.4926) lr 1.9980e-03 eta 0:33:12
epoch [5/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2773 (0.8304) acc 93.7500 (93.4375) lr 1.9980e-03 eta 0:33:08
epoch [5/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0775 (0.8272) acc 96.8750 (93.3882) lr 1.9980e-03 eta 0:33:04
epoch [5/50] batch [100/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.4478 (0.8791) acc 96.8750 (93.3438) lr 1.9980e-03 eta 0:33:01
epoch [5/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.5889 (0.8720) acc 90.6250 (93.3036) lr 1.9980e-03 eta 0:32:58
epoch [5/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.5395 (0.8706) acc 93.7500 (93.2102) lr 1.9980e-03 eta 0:32:55
epoch [5/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.3282 (0.8707) acc 93.7500 (93.1250) lr 1.9980e-03 eta 0:32:52
epoch [5/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.5030 (0.8678) acc 96.8750 (93.1510) lr 1.9980e-03 eta 0:32:49
epoch [5/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0226 (0.8461) acc 100.0000 (93.2500) lr 1.9980e-03 eta 0:32:46
epoch [5/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.7830 (0.8604) acc 93.7500 (93.2212) lr 1.9980e-03 eta 0:32:44
epoch [5/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.2315 (0.8552) acc 96.8750 (93.3102) lr 1.9980e-03 eta 0:32:41
epoch [5/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.2063 (0.8399) acc 93.7500 (93.3482) lr 1.9980e-03 eta 0:32:39
epoch [5/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.6687 (0.8311) acc 96.8750 (93.4052) lr 1.9980e-03 eta 0:32:37
epoch [5/50] batch [150/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2702 (0.8205) acc 93.7500 (93.3958) lr 1.9980e-03 eta 0:32:35
epoch [5/50] batch [155/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0009 (0.8161) acc 100.0000 (93.3065) lr 1.9980e-03 eta 0:32:33
epoch [5/50] batch [160/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.7031 (0.8360) acc 90.6250 (93.1836) lr 1.9980e-03 eta 0:32:31
epoch [5/50] batch [165/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.4239 (0.8226) acc 93.7500 (93.2386) lr 1.9980e-03 eta 0:32:29
epoch [5/50] batch [170/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.4758 (0.8222) acc 90.6250 (93.2721) lr 1.9980e-03 eta 0:32:27
epoch [5/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.3794 (0.8144) acc 93.7500 (93.2500) lr 1.9980e-03 eta 0:32:26
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [5/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 1.0197 (0.8060) acc 90.6250 (93.3160) lr 1.9921e-03 eta 0:32:24
在 *val* 集上测试
=> result
* total: 824
* correct: 765
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 89.5%
=> per-class result
* class: 0 (face)	total: 44	correct: 42	acc: 95.5%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 2	acc: 50.0%
* class: 6 (ant)	total: 4	correct: 4	acc: 100.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 4	acc: 66.7%
* class: 22 (chandelier)	total: 11	correct: 9	acc: 81.8%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 6	acc: 85.7%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 2	acc: 28.6%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 5	acc: 100.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 7	acc: 63.6%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 5	acc: 83.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 90.1%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model.pth.tar-5
epoch [6/50] batch [5/180] time 0.237 (0.350) data 0.000 (0.112) loss 0.1013 (0.3420) acc 96.8750 (93.7500) lr 1.9921e-03 eta 0:47:10
epoch [6/50] batch [10/180] time 0.237 (0.294) data 0.000 (0.056) loss 1.6359 (0.7017) acc 87.5000 (92.1875) lr 1.9921e-03 eta 0:39:34
epoch [6/50] batch [15/180] time 0.237 (0.275) data 0.000 (0.037) loss 1.4302 (0.6981) acc 93.7500 (93.1250) lr 1.9921e-03 eta 0:37:01
epoch [6/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.028) loss 0.3230 (0.5760) acc 90.6250 (93.7500) lr 1.9921e-03 eta 0:35:44
epoch [6/50] batch [25/180] time 0.237 (0.260) data 0.000 (0.022) loss 1.9567 (0.5606) acc 87.5000 (94.1250) lr 1.9921e-03 eta 0:34:58
epoch [6/50] batch [30/180] time 0.237 (0.256) data 0.000 (0.019) loss 0.0014 (0.6394) acc 100.0000 (93.7500) lr 1.9921e-03 eta 0:34:26
epoch [6/50] batch [35/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.6652 (0.6274) acc 90.6250 (93.6607) lr 1.9921e-03 eta 0:34:03
epoch [6/50] batch [40/180] time 0.238 (0.251) data 0.000 (0.014) loss 0.8430 (0.6435) acc 96.8750 (93.5938) lr 1.9921e-03 eta 0:33:46
epoch [6/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.9240 (0.6715) acc 87.5000 (93.3333) lr 1.9921e-03 eta 0:33:32
epoch [6/50] batch [50/180] time 0.238 (0.249) data 0.000 (0.011) loss 1.1165 (0.6470) acc 87.5000 (93.5000) lr 1.9921e-03 eta 0:33:21
epoch [6/50] batch [55/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.0797 (0.6121) acc 96.8750 (93.7500) lr 1.9921e-03 eta 0:33:12
epoch [6/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.009) loss 1.8565 (0.6473) acc 84.3750 (93.4375) lr 1.9921e-03 eta 0:33:04
epoch [6/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.4707 (0.6206) acc 90.6250 (93.4135) lr 1.9921e-03 eta 0:32:57
epoch [6/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.5009 (0.6131) acc 96.8750 (93.4821) lr 1.9921e-03 eta 0:32:50
epoch [6/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1362 (0.5930) acc 90.6250 (93.5417) lr 1.9921e-03 eta 0:32:45
epoch [6/50] batch [80/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.4245 (0.5768) acc 90.6250 (93.5156) lr 1.9921e-03 eta 0:32:40
epoch [6/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.8127 (0.5601) acc 90.6250 (93.4191) lr 1.9921e-03 eta 0:32:35
epoch [6/50] batch [90/180] time 0.237 (0.244) data 0.000 (0.006) loss 1.8982 (0.5850) acc 87.5000 (93.3333) lr 1.9921e-03 eta 0:32:31
epoch [6/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2197 (0.5735) acc 96.8750 (93.3882) lr 1.9921e-03 eta 0:32:27
epoch [6/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.006) loss 2.2261 (0.5794) acc 87.5000 (93.4375) lr 1.9921e-03 eta 0:32:24
epoch [6/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.005) loss 2.5984 (0.6124) acc 84.3750 (93.3333) lr 1.9921e-03 eta 0:32:20
epoch [6/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.9754 (0.6230) acc 90.6250 (93.1818) lr 1.9921e-03 eta 0:32:17
epoch [6/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 1.2530 (0.6267) acc 87.5000 (93.0978) lr 1.9921e-03 eta 0:32:14
epoch [6/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0038 (0.6084) acc 100.0000 (93.1510) lr 1.9921e-03 eta 0:32:11
epoch [6/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.6258 (0.5952) acc 90.6250 (93.2250) lr 1.9921e-03 eta 0:32:08
epoch [6/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 1.2545 (0.5931) acc 93.7500 (93.2692) lr 1.9921e-03 eta 0:32:06
epoch [6/50] batch [135/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.3178 (0.5756) acc 93.7500 (93.4028) lr 1.9921e-03 eta 0:32:03
epoch [6/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.3084 (0.5594) acc 96.8750 (93.5714) lr 1.9921e-03 eta 0:32:01
epoch [6/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.7184 (0.5689) acc 90.6250 (93.5560) lr 1.9921e-03 eta 0:31:59
epoch [6/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 1.3575 (0.5737) acc 90.6250 (93.4792) lr 1.9921e-03 eta 0:31:57
epoch [6/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0064 (0.5627) acc 100.0000 (93.5484) lr 1.9921e-03 eta 0:31:55
epoch [6/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4846 (0.5564) acc 90.6250 (93.5156) lr 1.9921e-03 eta 0:31:53
epoch [6/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1024 (0.5520) acc 93.7500 (93.5417) lr 1.9921e-03 eta 0:31:51
epoch [6/50] batch [170/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4331 (0.5500) acc 93.7500 (93.5478) lr 1.9921e-03 eta 0:31:49
epoch [6/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.3607 (0.5493) acc 96.8750 (93.5714) lr 1.9921e-03 eta 0:31:47
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [6/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.2890 (0.5447) acc 93.7500 (93.5069) lr 1.0000e-05 eta 0:31:45
在 *val* 集上测试
=> result
* total: 824
* correct: 765
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 89.1%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 6	acc: 85.7%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 4	acc: 57.1%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 9	acc: 100.0%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 6	acc: 54.5%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 6	acc: 85.7%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 4	acc: 80.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.6%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [7/50] batch [5/180] time 0.237 (0.339) data 0.000 (0.101) loss 0.6520 (0.3593) acc 96.8750 (95.6250) lr 1.0000e-05 eta 0:44:45
epoch [7/50] batch [10/180] time 0.238 (0.288) data 0.000 (0.050) loss 1.1119 (0.5190) acc 87.5000 (95.3125) lr 1.0000e-05 eta 0:38:00
epoch [7/50] batch [15/180] time 0.238 (0.271) data 0.000 (0.034) loss 0.0495 (0.4516) acc 96.8750 (94.5833) lr 1.0000e-05 eta 0:35:44
epoch [7/50] batch [20/180] time 0.237 (0.263) data 0.000 (0.025) loss 0.1080 (0.3996) acc 96.8750 (94.6875) lr 1.0000e-05 eta 0:34:35
epoch [7/50] batch [25/180] time 0.237 (0.258) data 0.000 (0.020) loss 0.0223 (0.3408) acc 100.0000 (95.3750) lr 1.0000e-05 eta 0:33:54
epoch [7/50] batch [30/180] time 0.238 (0.254) data 0.000 (0.017) loss 1.5302 (0.4195) acc 84.3750 (94.6875) lr 1.0000e-05 eta 0:33:26
epoch [7/50] batch [35/180] time 0.237 (0.252) data 0.000 (0.015) loss 0.9477 (0.4310) acc 90.6250 (94.3750) lr 1.0000e-05 eta 0:33:06
epoch [7/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.0322 (0.4603) acc 96.8750 (94.1406) lr 1.0000e-05 eta 0:32:50
epoch [7/50] batch [45/180] time 0.237 (0.249) data 0.000 (0.011) loss 1.4485 (0.4920) acc 90.6250 (94.0278) lr 1.0000e-05 eta 0:32:37
epoch [7/50] batch [50/180] time 0.238 (0.247) data 0.000 (0.010) loss 0.2739 (0.4753) acc 93.7500 (94.0625) lr 1.0000e-05 eta 0:32:27
epoch [7/50] batch [55/180] time 0.237 (0.247) data 0.000 (0.009) loss 1.0676 (0.4758) acc 87.5000 (93.9773) lr 1.0000e-05 eta 0:32:19
epoch [7/50] batch [60/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.2549 (0.4819) acc 93.7500 (93.8542) lr 1.0000e-05 eta 0:32:11
epoch [7/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1086 (0.4801) acc 96.8750 (93.7981) lr 1.0000e-05 eta 0:32:05
epoch [7/50] batch [70/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.2810 (0.4772) acc 96.8750 (93.9732) lr 1.0000e-05 eta 0:32:00
epoch [7/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0002 (0.4626) acc 100.0000 (94.2500) lr 1.0000e-05 eta 0:31:55
epoch [7/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.5426 (0.4582) acc 93.7500 (94.2578) lr 1.0000e-05 eta 0:31:50
epoch [7/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2539 (0.4436) acc 90.6250 (94.1176) lr 1.0000e-05 eta 0:31:46
epoch [7/50] batch [90/180] time 0.238 (0.243) data 0.000 (0.006) loss 1.1868 (0.4595) acc 90.6250 (94.1319) lr 1.0000e-05 eta 0:31:43
epoch [7/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.0269 (0.4601) acc 100.0000 (94.1776) lr 1.0000e-05 eta 0:31:39
epoch [7/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.005) loss 1.3102 (0.4666) acc 93.7500 (94.1250) lr 1.0000e-05 eta 0:31:36
epoch [7/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 1.0030 (0.4640) acc 96.8750 (94.1964) lr 1.0000e-05 eta 0:31:33
epoch [7/50] batch [110/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.5000 (0.4613) acc 90.6250 (94.2045) lr 1.0000e-05 eta 0:31:31
epoch [7/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2964 (0.4575) acc 93.7500 (94.1848) lr 1.0000e-05 eta 0:31:28
epoch [7/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.6816 (0.4598) acc 87.5000 (94.0625) lr 1.0000e-05 eta 0:31:26
epoch [7/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.1222 (0.4604) acc 93.7500 (94.0500) lr 1.0000e-05 eta 0:31:23
epoch [7/50] batch [130/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.2647 (0.4503) acc 96.8750 (94.1346) lr 1.0000e-05 eta 0:31:21
epoch [7/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0230 (0.4442) acc 96.8750 (94.0972) lr 1.0000e-05 eta 0:31:19
epoch [7/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0001 (0.4457) acc 100.0000 (94.1295) lr 1.0000e-05 eta 0:31:17
epoch [7/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 1.0227 (0.4481) acc 93.7500 (94.0733) lr 1.0000e-05 eta 0:31:15
epoch [7/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.2591 (0.4477) acc 96.8750 (94.0625) lr 1.0000e-05 eta 0:31:12
epoch [7/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 1.2644 (0.4445) acc 81.2500 (94.0323) lr 1.0000e-05 eta 0:31:10
epoch [7/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.2994 (0.4406) acc 96.8750 (94.0430) lr 1.0000e-05 eta 0:31:08
epoch [7/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.1020 (0.4341) acc 96.8750 (94.0720) lr 1.0000e-05 eta 0:31:07
epoch [7/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.7088 (0.4355) acc 90.6250 (94.0625) lr 1.0000e-05 eta 0:31:05
epoch [7/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4326 (0.4303) acc 90.6250 (94.0536) lr 1.0000e-05 eta 0:31:03
Adjusting learning rate of group 0 to 1.9921e-03.
epoch [7/50] batch [180/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.3146 (0.4383) acc 87.5000 (93.8368) lr 1.9921e-03 eta 0:31:01
在 *val* 集上测试
=> result
* total: 824
* correct: 763
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 88.8%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 6	acc: 85.7%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 6	acc: 54.5%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 6	acc: 85.7%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 4	acc: 80.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.3%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [8/50] batch [5/180] time 0.238 (0.347) data 0.000 (0.109) loss 0.0031 (0.1946) acc 100.0000 (94.3750) lr 1.9921e-03 eta 0:44:46
epoch [8/50] batch [10/180] time 0.238 (0.293) data 0.000 (0.055) loss 0.8577 (0.2169) acc 87.5000 (94.3750) lr 1.9921e-03 eta 0:37:42
epoch [8/50] batch [15/180] time 0.238 (0.274) data 0.000 (0.036) loss 0.6090 (0.2962) acc 96.8750 (94.7917) lr 1.9921e-03 eta 0:35:19
epoch [8/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.027) loss 0.1468 (0.2834) acc 93.7500 (94.2188) lr 1.9921e-03 eta 0:34:08
epoch [8/50] batch [25/180] time 0.238 (0.260) data 0.000 (0.022) loss 0.0489 (0.2986) acc 96.8750 (94.3750) lr 1.9921e-03 eta 0:33:24
epoch [8/50] batch [30/180] time 0.238 (0.256) data 0.000 (0.018) loss 0.2962 (0.3325) acc 90.6250 (93.8542) lr 1.9921e-03 eta 0:32:55
epoch [8/50] batch [35/180] time 0.238 (0.254) data 0.000 (0.016) loss 0.3352 (0.3198) acc 96.8750 (94.1964) lr 1.9921e-03 eta 0:32:33
epoch [8/50] batch [40/180] time 0.238 (0.252) data 0.000 (0.014) loss 0.2878 (0.3104) acc 96.8750 (94.2969) lr 1.9921e-03 eta 0:32:17
epoch [8/50] batch [45/180] time 0.238 (0.250) data 0.000 (0.012) loss 0.0002 (0.3317) acc 100.0000 (94.2361) lr 1.9921e-03 eta 0:32:04
epoch [8/50] batch [50/180] time 0.238 (0.249) data 0.000 (0.011) loss 0.2599 (0.3500) acc 87.5000 (94.1875) lr 1.9921e-03 eta 0:31:53
epoch [8/50] batch [55/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.5029 (0.3559) acc 90.6250 (94.0909) lr 1.9921e-03 eta 0:31:44
epoch [8/50] batch [60/180] time 0.238 (0.247) data 0.000 (0.009) loss 1.6233 (0.3867) acc 93.7500 (94.1667) lr 1.9921e-03 eta 0:31:37
epoch [8/50] batch [65/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.1082 (0.3982) acc 96.8750 (94.1346) lr 1.9921e-03 eta 0:31:30
epoch [8/50] batch [70/180] time 0.238 (0.246) data 0.000 (0.008) loss 0.5765 (0.4035) acc 90.6250 (93.9732) lr 1.9921e-03 eta 0:31:24
epoch [8/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.3712 (0.4018) acc 90.6250 (93.8750) lr 1.9921e-03 eta 0:31:19
epoch [8/50] batch [80/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.3625 (0.4202) acc 90.6250 (93.7500) lr 1.9921e-03 eta 0:31:14
epoch [8/50] batch [85/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.0550 (0.4310) acc 96.8750 (93.6765) lr 1.9921e-03 eta 0:31:10
epoch [8/50] batch [90/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.0020 (0.4381) acc 100.0000 (93.6111) lr 1.9921e-03 eta 0:31:06
epoch [8/50] batch [95/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.0160 (0.4232) acc 100.0000 (93.6842) lr 1.9921e-03 eta 0:31:02
epoch [8/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0379 (0.4165) acc 96.8750 (93.6562) lr 1.9921e-03 eta 0:30:59
epoch [8/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.005) loss 1.3673 (0.4500) acc 90.6250 (93.3929) lr 1.9921e-03 eta 0:30:56
epoch [8/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.3626 (0.4486) acc 90.6250 (93.3523) lr 1.9921e-03 eta 0:30:52
epoch [8/50] batch [115/180] time 0.238 (0.243) data 0.000 (0.005) loss 1.3893 (0.4492) acc 87.5000 (93.2880) lr 1.9921e-03 eta 0:30:50
epoch [8/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2493 (0.4432) acc 93.7500 (93.2812) lr 1.9921e-03 eta 0:30:47
epoch [8/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.3487 (0.4450) acc 93.7500 (93.2000) lr 1.9921e-03 eta 0:30:44
epoch [8/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 1.3698 (0.4462) acc 90.6250 (93.2212) lr 1.9921e-03 eta 0:30:41
epoch [8/50] batch [135/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0143 (0.4498) acc 100.0000 (93.2407) lr 1.9921e-03 eta 0:30:39
epoch [8/50] batch [140/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.3120 (0.4444) acc 96.8750 (93.2812) lr 1.9921e-03 eta 0:30:37
epoch [8/50] batch [145/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0023 (0.4341) acc 100.0000 (93.3836) lr 1.9921e-03 eta 0:30:34
epoch [8/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.6781 (0.4283) acc 96.8750 (93.4583) lr 1.9921e-03 eta 0:30:32
epoch [8/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.3279 (0.4233) acc 90.6250 (93.4879) lr 1.9921e-03 eta 0:30:30
epoch [8/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1189 (0.4197) acc 93.7500 (93.5156) lr 1.9921e-03 eta 0:30:28
epoch [8/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 1.4381 (0.4217) acc 84.3750 (93.5038) lr 1.9921e-03 eta 0:30:26
epoch [8/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 1.1079 (0.4295) acc 87.5000 (93.4926) lr 1.9921e-03 eta 0:30:24
epoch [8/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.3300 (0.4330) acc 90.6250 (93.5179) lr 1.9921e-03 eta 0:30:22
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [8/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.5886 (0.4309) acc 93.7500 (93.5764) lr 1.9823e-03 eta 0:30:20
在 *val* 集上测试
=> result
* total: 824
* correct: 750
* accuracy: 91.0%
* error: 9.0%
* macro_f1: 86.3%
=> per-class result
* class: 0 (face)	total: 44	correct: 43	acc: 97.7%
* class: 1 (leopard)	total: 20	correct: 18	acc: 90.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 79	acc: 98.8%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 2	acc: 50.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 5	acc: 83.3%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 6	acc: 85.7%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 8	acc: 100.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 4	acc: 80.0%
* class: 37 (euphonium)	total: 6	correct: 3	acc: 50.0%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 9	acc: 90.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 7	acc: 87.5%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 3	acc: 75.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 0	acc: 0.0%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 5	acc: 62.5%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 4	acc: 80.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 4	acc: 66.7%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 86.7%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [9/50] batch [5/180] time 0.239 (0.348) data 0.000 (0.109) loss 0.3639 (0.2724) acc 90.6250 (92.5000) lr 1.9823e-03 eta 0:43:45
epoch [9/50] batch [10/180] time 0.238 (0.293) data 0.000 (0.055) loss 0.2506 (0.2357) acc 93.7500 (94.0625) lr 1.9823e-03 eta 0:36:50
epoch [9/50] batch [15/180] time 0.238 (0.274) data 0.000 (0.036) loss 0.0017 (0.2409) acc 100.0000 (93.9583) lr 1.9823e-03 eta 0:34:30
epoch [9/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.027) loss 0.0858 (0.3556) acc 96.8750 (92.9688) lr 1.9823e-03 eta 0:33:19
epoch [9/50] batch [25/180] time 0.237 (0.260) data 0.000 (0.022) loss 0.0874 (0.3626) acc 96.8750 (93.1250) lr 1.9823e-03 eta 0:32:37
epoch [9/50] batch [30/180] time 0.238 (0.256) data 0.000 (0.018) loss 0.4676 (0.4020) acc 87.5000 (92.3958) lr 1.9823e-03 eta 0:32:08
epoch [9/50] batch [35/180] time 0.238 (0.253) data 0.000 (0.016) loss 0.4339 (0.3889) acc 96.8750 (92.4107) lr 1.9823e-03 eta 0:31:47
epoch [9/50] batch [40/180] time 0.238 (0.251) data 0.000 (0.014) loss 0.0000 (0.4168) acc 100.0000 (92.6562) lr 1.9823e-03 eta 0:31:31
epoch [9/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.012) loss 1.3077 (0.4292) acc 90.6250 (92.8472) lr 1.9823e-03 eta 0:31:18
epoch [9/50] batch [50/180] time 0.237 (0.249) data 0.000 (0.011) loss 0.2648 (0.4526) acc 93.7500 (92.9375) lr 1.9823e-03 eta 0:31:07
epoch [9/50] batch [55/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.7427 (0.4380) acc 84.3750 (92.8977) lr 1.9823e-03 eta 0:30:58
epoch [9/50] batch [60/180] time 0.238 (0.247) data 0.000 (0.009) loss 0.2113 (0.4210) acc 96.8750 (92.9688) lr 1.9823e-03 eta 0:30:51
epoch [9/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.0482 (0.3987) acc 96.8750 (93.1250) lr 1.9823e-03 eta 0:30:45
epoch [9/50] batch [70/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.9250 (0.4177) acc 87.5000 (92.9911) lr 1.9823e-03 eta 0:30:39
epoch [9/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.5983 (0.4097) acc 87.5000 (93.0000) lr 1.9823e-03 eta 0:30:34
epoch [9/50] batch [80/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.3572 (0.4177) acc 96.8750 (93.1250) lr 1.9823e-03 eta 0:30:29
epoch [9/50] batch [85/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.1980 (0.4227) acc 96.8750 (93.1618) lr 1.9823e-03 eta 0:30:25
epoch [9/50] batch [90/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.4533 (0.4277) acc 96.8750 (93.1944) lr 1.9823e-03 eta 0:30:21
epoch [9/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.6155 (0.4177) acc 93.7500 (93.2895) lr 1.9823e-03 eta 0:30:17
epoch [9/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.0128 (0.4069) acc 100.0000 (93.3750) lr 1.9823e-03 eta 0:30:14
epoch [9/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.3482 (0.4016) acc 90.6250 (93.2738) lr 1.9823e-03 eta 0:30:11
epoch [9/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.1149 (0.3943) acc 96.8750 (93.3807) lr 1.9823e-03 eta 0:30:08
epoch [9/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.7745 (0.3962) acc 90.6250 (93.4511) lr 1.9823e-03 eta 0:30:05
epoch [9/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.3375 (0.3958) acc 93.7500 (93.5677) lr 1.9823e-03 eta 0:30:02
epoch [9/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.8562 (0.3901) acc 96.8750 (93.7000) lr 1.9823e-03 eta 0:30:00
epoch [9/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.2474 (0.3879) acc 90.6250 (93.7740) lr 1.9823e-03 eta 0:29:57
epoch [9/50] batch [135/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.3487 (0.3821) acc 93.7500 (93.7963) lr 1.9823e-03 eta 0:29:55
epoch [9/50] batch [140/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0696 (0.3806) acc 96.8750 (93.7500) lr 1.9823e-03 eta 0:29:52
epoch [9/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.4051 (0.3778) acc 87.5000 (93.7716) lr 1.9823e-03 eta 0:29:50
epoch [9/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4317 (0.3873) acc 93.7500 (93.7500) lr 1.9823e-03 eta 0:29:48
epoch [9/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1443 (0.3837) acc 96.8750 (93.7298) lr 1.9823e-03 eta 0:29:46
epoch [9/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1520 (0.3825) acc 90.6250 (93.6719) lr 1.9823e-03 eta 0:29:44
epoch [9/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.3436 (0.3826) acc 93.7500 (93.6364) lr 1.9823e-03 eta 0:29:42
epoch [9/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0082 (0.3797) acc 100.0000 (93.6581) lr 1.9823e-03 eta 0:29:40
epoch [9/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0537 (0.3800) acc 96.8750 (93.6786) lr 1.9823e-03 eta 0:29:38
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [9/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1388 (0.3777) acc 96.8750 (93.7674) lr 1.0000e-05 eta 0:29:36
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.4%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 4	acc: 80.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 23	acc: 95.8%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.8%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [10/50] batch [5/180] time 0.238 (0.342) data 0.000 (0.101) loss 0.1900 (0.3346) acc 96.8750 (95.0000) lr 1.0000e-05 eta 0:42:04
epoch [10/50] batch [10/180] time 0.237 (0.290) data 0.000 (0.050) loss 0.0425 (0.2855) acc 96.8750 (95.3125) lr 1.0000e-05 eta 0:35:36
epoch [10/50] batch [15/180] time 0.237 (0.272) data 0.000 (0.034) loss 0.2412 (0.3092) acc 93.7500 (95.0000) lr 1.0000e-05 eta 0:33:25
epoch [10/50] batch [20/180] time 0.238 (0.264) data 0.000 (0.025) loss 1.1911 (0.3341) acc 87.5000 (94.3750) lr 1.0000e-05 eta 0:32:20
epoch [10/50] batch [25/180] time 0.237 (0.258) data 0.000 (0.020) loss 0.3527 (0.2843) acc 93.7500 (95.0000) lr 1.0000e-05 eta 0:31:40
epoch [10/50] batch [30/180] time 0.237 (0.255) data 0.000 (0.017) loss 0.3620 (0.3316) acc 96.8750 (94.3750) lr 1.0000e-05 eta 0:31:13
epoch [10/50] batch [35/180] time 0.237 (0.252) data 0.000 (0.014) loss 0.7515 (0.3372) acc 87.5000 (94.5536) lr 1.0000e-05 eta 0:30:53
epoch [10/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.013) loss 0.2700 (0.3100) acc 96.8750 (94.7656) lr 1.0000e-05 eta 0:30:39
epoch [10/50] batch [45/180] time 0.237 (0.249) data 0.000 (0.011) loss 0.3139 (0.2985) acc 90.6250 (94.9306) lr 1.0000e-05 eta 0:30:27
epoch [10/50] batch [50/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.0005 (0.3036) acc 100.0000 (95.0625) lr 1.0000e-05 eta 0:30:17
epoch [10/50] batch [55/180] time 0.238 (0.247) data 0.000 (0.009) loss 0.1513 (0.3195) acc 96.8750 (95.0568) lr 1.0000e-05 eta 0:30:09
epoch [10/50] batch [60/180] time 0.238 (0.246) data 0.000 (0.008) loss 0.2413 (0.3121) acc 93.7500 (94.9479) lr 1.0000e-05 eta 0:30:02
epoch [10/50] batch [65/180] time 0.238 (0.246) data 0.000 (0.008) loss 0.6447 (0.3017) acc 93.7500 (95.0481) lr 1.0000e-05 eta 0:29:56
epoch [10/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.2761 (0.3086) acc 90.6250 (94.9554) lr 1.0000e-05 eta 0:29:51
epoch [10/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.5342 (0.3113) acc 93.7500 (94.9583) lr 1.0000e-05 eta 0:29:46
epoch [10/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.3815 (0.3260) acc 96.8750 (94.9219) lr 1.0000e-05 eta 0:29:42
epoch [10/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.0343 (0.3268) acc 96.8750 (94.8897) lr 1.0000e-05 eta 0:29:37
epoch [10/50] batch [90/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.1426 (0.3228) acc 93.7500 (94.8264) lr 1.0000e-05 eta 0:29:34
epoch [10/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.7980 (0.3354) acc 93.7500 (94.8026) lr 1.0000e-05 eta 0:29:30
epoch [10/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.0747 (0.3578) acc 96.8750 (94.5938) lr 1.0000e-05 eta 0:29:27
epoch [10/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.3626 (0.3554) acc 93.7500 (94.4940) lr 1.0000e-05 eta 0:29:24
epoch [10/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.4400 (0.3470) acc 87.5000 (94.5455) lr 1.0000e-05 eta 0:29:21
epoch [10/50] batch [115/180] time 0.238 (0.242) data 0.001 (0.004) loss 0.0088 (0.3477) acc 100.0000 (94.5652) lr 1.0000e-05 eta 0:29:18
epoch [10/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.3234 (0.3425) acc 96.8750 (94.6354) lr 1.0000e-05 eta 0:29:16
epoch [10/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.2224 (0.3319) acc 93.7500 (94.7250) lr 1.0000e-05 eta 0:29:13
epoch [10/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.3382 (0.3309) acc 93.7500 (94.7356) lr 1.0000e-05 eta 0:29:11
epoch [10/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.8625 (0.3361) acc 96.8750 (94.6991) lr 1.0000e-05 eta 0:29:09
epoch [10/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1999 (0.3371) acc 93.7500 (94.6875) lr 1.0000e-05 eta 0:29:07
epoch [10/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0981 (0.3290) acc 96.8750 (94.7845) lr 1.0000e-05 eta 0:29:04
epoch [10/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.2765 (0.3231) acc 90.6250 (94.7292) lr 1.0000e-05 eta 0:29:02
epoch [10/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 1.7049 (0.3305) acc 93.7500 (94.7177) lr 1.0000e-05 eta 0:29:00
epoch [10/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1195 (0.3387) acc 93.7500 (94.6289) lr 1.0000e-05 eta 0:28:58
epoch [10/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.3219 (0.3354) acc 90.6250 (94.6212) lr 1.0000e-05 eta 0:28:56
epoch [10/50] batch [170/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0003 (0.3325) acc 100.0000 (94.6507) lr 1.0000e-05 eta 0:28:54
epoch [10/50] batch [175/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.2187 (0.3457) acc 96.8750 (94.5536) lr 1.0000e-05 eta 0:28:53
Adjusting learning rate of group 0 to 1.9823e-03.
epoch [10/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.4676 (0.3447) acc 87.5000 (94.5139) lr 1.9823e-03 eta 0:28:51
在 *val* 集上测试
=> result
* total: 824
* correct: 766
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 89.2%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 5	acc: 100.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 4	acc: 80.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 8	acc: 100.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 5	acc: 83.3%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 23	acc: 95.8%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.7%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model.pth.tar-10
epoch [11/50] batch [5/180] time 0.237 (0.339) data 0.000 (0.099) loss 0.0470 (0.3743) acc 96.8750 (91.8750) lr 1.9823e-03 eta 0:40:35
epoch [11/50] batch [10/180] time 0.238 (0.288) data 0.000 (0.050) loss 0.6693 (0.4474) acc 84.3750 (91.2500) lr 1.9823e-03 eta 0:34:31
epoch [11/50] batch [15/180] time 0.238 (0.271) data 0.000 (0.033) loss 0.3661 (0.4230) acc 93.7500 (91.2500) lr 1.9823e-03 eta 0:32:28
epoch [11/50] batch [20/180] time 0.237 (0.263) data 0.000 (0.025) loss 0.0283 (0.3643) acc 96.8750 (92.0312) lr 1.9823e-03 eta 0:31:26
epoch [11/50] batch [25/180] time 0.237 (0.258) data 0.000 (0.020) loss 0.7845 (0.3589) acc 93.7500 (92.3750) lr 1.9823e-03 eta 0:30:49
epoch [11/50] batch [30/180] time 0.237 (0.254) data 0.000 (0.017) loss 0.0681 (0.3088) acc 96.8750 (93.1250) lr 1.9823e-03 eta 0:30:23
epoch [11/50] batch [35/180] time 0.238 (0.252) data 0.000 (0.014) loss 0.0036 (0.2751) acc 100.0000 (93.7500) lr 1.9823e-03 eta 0:30:05
epoch [11/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.0725 (0.2781) acc 96.8750 (94.0625) lr 1.9823e-03 eta 0:29:51
epoch [11/50] batch [45/180] time 0.238 (0.249) data 0.000 (0.011) loss 0.0750 (0.2853) acc 96.8750 (94.3750) lr 1.9823e-03 eta 0:29:39
epoch [11/50] batch [50/180] time 0.237 (0.248) data 0.000 (0.010) loss 0.3114 (0.3013) acc 87.5000 (94.1250) lr 1.9823e-03 eta 0:29:30
epoch [11/50] batch [55/180] time 0.237 (0.247) data 0.000 (0.009) loss 0.6916 (0.3056) acc 93.7500 (94.2614) lr 1.9823e-03 eta 0:29:22
epoch [11/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.6406 (0.3113) acc 90.6250 (94.0625) lr 1.9823e-03 eta 0:29:15
epoch [11/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.0135 (0.3105) acc 100.0000 (94.2788) lr 1.9823e-03 eta 0:29:09
epoch [11/50] batch [70/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.0298 (0.2980) acc 96.8750 (94.3304) lr 1.9823e-03 eta 0:29:04
epoch [11/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0288 (0.3037) acc 96.8750 (94.2083) lr 1.9823e-03 eta 0:29:00
epoch [11/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.2436 (0.2958) acc 93.7500 (94.2969) lr 1.9823e-03 eta 0:28:55
epoch [11/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0970 (0.2845) acc 96.8750 (94.3750) lr 1.9823e-03 eta 0:28:51
epoch [11/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.8712 (0.2952) acc 87.5000 (94.1667) lr 1.9823e-03 eta 0:28:48
epoch [11/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.3005 (0.2936) acc 96.8750 (94.3092) lr 1.9823e-03 eta 0:28:44
epoch [11/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.2166 (0.2911) acc 96.8750 (94.3125) lr 1.9823e-03 eta 0:28:41
epoch [11/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0537 (0.2941) acc 96.8750 (94.1964) lr 1.9823e-03 eta 0:28:38
epoch [11/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0780 (0.2928) acc 96.8750 (94.1477) lr 1.9823e-03 eta 0:28:36
epoch [11/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.2908 (0.3050) acc 93.7500 (93.9674) lr 1.9823e-03 eta 0:28:33
epoch [11/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.004) loss 1.1978 (0.3172) acc 90.6250 (93.9062) lr 1.9823e-03 eta 0:28:31
epoch [11/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.2035 (0.3164) acc 93.7500 (93.9500) lr 1.9823e-03 eta 0:28:28
epoch [11/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.6860 (0.3158) acc 90.6250 (93.9423) lr 1.9823e-03 eta 0:28:26
epoch [11/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1189 (0.3202) acc 93.7500 (93.8426) lr 1.9823e-03 eta 0:28:24
epoch [11/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4439 (0.3199) acc 93.7500 (93.8393) lr 1.9823e-03 eta 0:28:21
epoch [11/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0922 (0.3139) acc 96.8750 (93.9009) lr 1.9823e-03 eta 0:28:19
epoch [11/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4672 (0.3126) acc 93.7500 (93.9167) lr 1.9823e-03 eta 0:28:17
epoch [11/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.1073 (0.3086) acc 93.7500 (93.9516) lr 1.9823e-03 eta 0:28:15
epoch [11/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1694 (0.3097) acc 96.8750 (94.0234) lr 1.9823e-03 eta 0:28:13
epoch [11/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.2906 (0.3104) acc 90.6250 (94.0341) lr 1.9823e-03 eta 0:28:11
epoch [11/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2609 (0.3095) acc 93.7500 (93.9890) lr 1.9823e-03 eta 0:28:10
epoch [11/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 1.1268 (0.3292) acc 90.6250 (93.9286) lr 1.9823e-03 eta 0:28:08
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [11/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.4418 (0.3313) acc 90.6250 (93.9236) lr 1.9686e-03 eta 0:28:06
在 *val* 集上测试
=> result
* total: 824
* correct: 755
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 87.4%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 2	acc: 50.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 4	acc: 80.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 7	acc: 87.5%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 2	acc: 18.2%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 5	acc: 83.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 4	acc: 80.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 7	acc: 87.5%
* class: 93 (watch)	total: 24	correct: 23	acc: 95.8%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 88.0%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [12/50] batch [5/180] time 0.238 (0.333) data 0.000 (0.096) loss 0.7067 (0.5709) acc 81.2500 (90.6250) lr 1.9686e-03 eta 0:38:57
epoch [12/50] batch [10/180] time 0.238 (0.285) data 0.000 (0.048) loss 0.1164 (0.4467) acc 96.8750 (93.7500) lr 1.9686e-03 eta 0:33:20
epoch [12/50] batch [15/180] time 0.237 (0.269) data 0.000 (0.032) loss 0.4965 (0.4217) acc 87.5000 (93.5417) lr 1.9686e-03 eta 0:31:26
epoch [12/50] batch [20/180] time 0.238 (0.261) data 0.000 (0.024) loss 0.3608 (0.3858) acc 90.6250 (93.7500) lr 1.9686e-03 eta 0:30:29
epoch [12/50] batch [25/180] time 0.237 (0.257) data 0.000 (0.019) loss 0.1085 (0.3452) acc 90.6250 (93.7500) lr 1.9686e-03 eta 0:29:54
epoch [12/50] batch [30/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.9947 (0.3865) acc 87.5000 (93.0208) lr 1.9686e-03 eta 0:29:31
epoch [12/50] batch [35/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.1630 (0.3837) acc 96.8750 (92.9464) lr 1.9686e-03 eta 0:29:13
epoch [12/50] batch [40/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.0521 (0.3868) acc 96.8750 (93.2031) lr 1.9686e-03 eta 0:29:00
epoch [12/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0078 (0.3603) acc 100.0000 (93.4722) lr 1.9686e-03 eta 0:28:49
epoch [12/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.3810 (0.3356) acc 84.3750 (93.6250) lr 1.9686e-03 eta 0:28:41
epoch [12/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2930 (0.3288) acc 93.7500 (93.6932) lr 1.9686e-03 eta 0:28:33
epoch [12/50] batch [60/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1673 (0.3271) acc 93.7500 (93.7500) lr 1.9686e-03 eta 0:28:27
epoch [12/50] batch [65/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.1123 (0.3304) acc 93.7500 (93.5096) lr 1.9686e-03 eta 0:28:21
epoch [12/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0028 (0.3150) acc 100.0000 (93.7054) lr 1.9686e-03 eta 0:28:16
epoch [12/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0694 (0.3139) acc 96.8750 (93.7500) lr 1.9686e-03 eta 0:28:12
epoch [12/50] batch [80/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.6080 (0.3067) acc 90.6250 (93.8281) lr 1.9686e-03 eta 0:28:08
epoch [12/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2981 (0.3100) acc 93.7500 (93.6765) lr 1.9686e-03 eta 0:28:04
epoch [12/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0483 (0.3185) acc 96.8750 (93.7153) lr 1.9686e-03 eta 0:28:01
epoch [12/50] batch [95/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0075 (0.3044) acc 100.0000 (93.9474) lr 1.9686e-03 eta 0:27:58
epoch [12/50] batch [100/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0181 (0.2985) acc 100.0000 (93.9688) lr 1.9686e-03 eta 0:27:55
epoch [12/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1175 (0.3013) acc 90.6250 (93.8393) lr 1.9686e-03 eta 0:27:52
epoch [12/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0139 (0.2966) acc 100.0000 (93.9489) lr 1.9686e-03 eta 0:27:50
epoch [12/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0670 (0.3065) acc 93.7500 (93.9130) lr 1.9686e-03 eta 0:27:47
epoch [12/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.2044 (0.3018) acc 96.8750 (94.0104) lr 1.9686e-03 eta 0:27:45
epoch [12/50] batch [125/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0285 (0.2979) acc 96.8750 (94.0500) lr 1.9686e-03 eta 0:27:42
epoch [12/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1251 (0.2930) acc 93.7500 (94.1346) lr 1.9686e-03 eta 0:27:40
epoch [12/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4492 (0.2896) acc 93.7500 (94.1667) lr 1.9686e-03 eta 0:27:38
epoch [12/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1144 (0.2865) acc 96.8750 (94.0848) lr 1.9686e-03 eta 0:27:36
epoch [12/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.003) loss 1.3199 (0.3028) acc 93.7500 (94.0086) lr 1.9686e-03 eta 0:27:34
epoch [12/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4428 (0.2984) acc 87.5000 (94.0625) lr 1.9686e-03 eta 0:27:32
epoch [12/50] batch [155/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.1799 (0.2998) acc 93.7500 (93.9516) lr 1.9686e-03 eta 0:27:30
epoch [12/50] batch [160/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.3143 (0.3016) acc 96.8750 (93.9258) lr 1.9686e-03 eta 0:27:28
epoch [12/50] batch [165/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.1481 (0.3048) acc 96.8750 (93.9583) lr 1.9686e-03 eta 0:27:26
epoch [12/50] batch [170/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.1684 (0.3052) acc 96.8750 (94.0074) lr 1.9686e-03 eta 0:27:25
epoch [12/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2473 (0.3026) acc 90.6250 (94.0179) lr 1.9686e-03 eta 0:27:23
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [12/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.5464 (0.3035) acc 87.5000 (93.9931) lr 1.0000e-05 eta 0:27:21
在 *val* 集上测试
=> result
* total: 824
* correct: 765
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 88.7%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 2	acc: 50.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 4	acc: 66.7%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 4	acc: 57.1%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 4	acc: 66.7%
* class: 38 (ewer)	total: 8	correct: 7	acc: 87.5%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 8	acc: 72.7%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.0%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [13/50] batch [5/180] time 0.237 (0.357) data 0.000 (0.119) loss 0.2476 (0.1273) acc 93.7500 (96.2500) lr 1.0000e-05 eta 0:40:37
epoch [13/50] batch [10/180] time 0.238 (0.297) data 0.000 (0.060) loss 0.9253 (0.3699) acc 90.6250 (93.4375) lr 1.0000e-05 eta 0:33:49
epoch [13/50] batch [15/180] time 0.237 (0.277) data 0.000 (0.040) loss 0.2702 (0.3525) acc 90.6250 (92.9167) lr 1.0000e-05 eta 0:31:31
epoch [13/50] batch [20/180] time 0.237 (0.267) data 0.000 (0.030) loss 0.0408 (0.2791) acc 96.8750 (94.0625) lr 1.0000e-05 eta 0:30:21
epoch [13/50] batch [25/180] time 0.237 (0.261) data 0.000 (0.024) loss 0.3597 (0.3301) acc 93.7500 (93.7500) lr 1.0000e-05 eta 0:29:39
epoch [13/50] batch [30/180] time 0.238 (0.257) data 0.000 (0.020) loss 0.2247 (0.3195) acc 93.7500 (93.6458) lr 1.0000e-05 eta 0:29:11
epoch [13/50] batch [35/180] time 0.238 (0.254) data 0.000 (0.017) loss 0.3909 (0.2934) acc 96.8750 (94.1071) lr 1.0000e-05 eta 0:28:51
epoch [13/50] batch [40/180] time 0.237 (0.252) data 0.000 (0.015) loss 0.4604 (0.2973) acc 90.6250 (93.9844) lr 1.0000e-05 eta 0:28:35
epoch [13/50] batch [45/180] time 0.237 (0.251) data 0.000 (0.013) loss 0.0658 (0.2864) acc 96.8750 (94.1667) lr 1.0000e-05 eta 0:28:22
epoch [13/50] batch [50/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.5366 (0.2853) acc 87.5000 (93.9375) lr 1.0000e-05 eta 0:28:12
epoch [13/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0085 (0.2756) acc 100.0000 (94.0909) lr 1.0000e-05 eta 0:28:03
epoch [13/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.2558 (0.2908) acc 90.6250 (93.9583) lr 1.0000e-05 eta 0:27:56
epoch [13/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.1409 (0.2795) acc 96.8750 (93.9904) lr 1.0000e-05 eta 0:27:49
epoch [13/50] batch [70/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.3598 (0.2876) acc 90.6250 (93.9732) lr 1.0000e-05 eta 0:27:43
epoch [13/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.2658 (0.2877) acc 90.6250 (93.9167) lr 1.0000e-05 eta 0:27:38
epoch [13/50] batch [80/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.0605 (0.2877) acc 96.8750 (93.9844) lr 1.0000e-05 eta 0:27:33
epoch [13/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0964 (0.2795) acc 96.8750 (94.1544) lr 1.0000e-05 eta 0:27:29
epoch [13/50] batch [90/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.1005 (0.2696) acc 93.7500 (94.2361) lr 1.0000e-05 eta 0:27:25
epoch [13/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.2841 (0.2677) acc 93.7500 (94.2434) lr 1.0000e-05 eta 0:27:22
epoch [13/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.5531 (0.2645) acc 96.8750 (94.3438) lr 1.0000e-05 eta 0:27:18
epoch [13/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.3314 (0.2765) acc 90.6250 (94.2857) lr 1.0000e-05 eta 0:27:15
epoch [13/50] batch [110/180] time 0.236 (0.243) data 0.000 (0.006) loss 0.1652 (0.2731) acc 90.6250 (94.2330) lr 1.0000e-05 eta 0:27:12
epoch [13/50] batch [115/180] time 0.236 (0.242) data 0.000 (0.005) loss 0.4187 (0.2755) acc 87.5000 (94.1576) lr 1.0000e-05 eta 0:27:09
epoch [13/50] batch [120/180] time 0.236 (0.242) data 0.000 (0.005) loss 0.1814 (0.2702) acc 96.8750 (94.2448) lr 1.0000e-05 eta 0:27:06
epoch [13/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1819 (0.2633) acc 96.8750 (94.3500) lr 1.0000e-05 eta 0:27:03
epoch [13/50] batch [130/180] time 0.236 (0.242) data 0.000 (0.005) loss 0.1602 (0.2594) acc 90.6250 (94.3750) lr 1.0000e-05 eta 0:27:00
epoch [13/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.005) loss 0.0027 (0.2546) acc 100.0000 (94.4213) lr 1.0000e-05 eta 0:26:58
epoch [13/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0758 (0.2559) acc 96.8750 (94.4643) lr 1.0000e-05 eta 0:26:56
epoch [13/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1658 (0.2557) acc 93.7500 (94.4828) lr 1.0000e-05 eta 0:26:53
epoch [13/50] batch [150/180] time 0.236 (0.241) data 0.000 (0.004) loss 0.2746 (0.2510) acc 90.6250 (94.5208) lr 1.0000e-05 eta 0:26:51
epoch [13/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.5259 (0.2614) acc 87.5000 (94.3952) lr 1.0000e-05 eta 0:26:49
epoch [13/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1930 (0.2592) acc 96.8750 (94.4531) lr 1.0000e-05 eta 0:26:47
epoch [13/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.004) loss 0.0531 (0.2578) acc 96.8750 (94.5076) lr 1.0000e-05 eta 0:26:45
epoch [13/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.004) loss 0.0410 (0.2580) acc 100.0000 (94.5221) lr 1.0000e-05 eta 0:26:43
epoch [13/50] batch [175/180] time 0.236 (0.240) data 0.000 (0.004) loss 0.8895 (0.2594) acc 87.5000 (94.5357) lr 1.0000e-05 eta 0:26:41
Adjusting learning rate of group 0 to 1.9686e-03.
epoch [13/50] batch [180/180] time 0.236 (0.240) data 0.000 (0.003) loss 0.2028 (0.2614) acc 87.5000 (94.5139) lr 1.9686e-03 eta 0:26:39
在 *val* 集上测试
=> result
* total: 824
* correct: 762
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 88.4%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 2	acc: 50.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 4	acc: 66.7%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 6	acc: 85.7%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 4	acc: 57.1%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 4	acc: 80.0%
* class: 37 (euphonium)	total: 6	correct: 4	acc: 66.7%
* class: 38 (ewer)	total: 8	correct: 7	acc: 87.5%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 2	acc: 50.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 8	acc: 72.7%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 3	acc: 75.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 4	acc: 66.7%
* class: 98 (wrench)	total: 4	correct: 3	acc: 75.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 88.5%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [14/50] batch [5/180] time 0.237 (0.343) data 0.000 (0.106) loss 0.1539 (0.2903) acc 93.7500 (94.3750) lr 1.9686e-03 eta 0:38:01
epoch [14/50] batch [10/180] time 0.237 (0.290) data 0.000 (0.053) loss 0.2507 (0.2897) acc 96.8750 (95.0000) lr 1.9686e-03 eta 0:32:06
epoch [14/50] batch [15/180] time 0.237 (0.272) data 0.000 (0.035) loss 1.3601 (0.3093) acc 93.7500 (95.6250) lr 1.9686e-03 eta 0:30:08
epoch [14/50] batch [20/180] time 0.237 (0.263) data 0.000 (0.027) loss 0.0272 (0.2860) acc 96.8750 (95.7812) lr 1.9686e-03 eta 0:29:07
epoch [14/50] batch [25/180] time 0.236 (0.258) data 0.000 (0.021) loss 0.3624 (0.2573) acc 93.7500 (95.7500) lr 1.9686e-03 eta 0:28:31
epoch [14/50] batch [30/180] time 0.237 (0.254) data 0.000 (0.018) loss 0.4050 (0.2777) acc 90.6250 (95.2083) lr 1.9686e-03 eta 0:28:06
epoch [14/50] batch [35/180] time 0.237 (0.252) data 0.000 (0.015) loss 0.0465 (0.2787) acc 100.0000 (95.0893) lr 1.9686e-03 eta 0:27:48
epoch [14/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.1393 (0.2602) acc 96.8750 (95.3906) lr 1.9686e-03 eta 0:27:34
epoch [14/50] batch [45/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.2543 (0.2496) acc 93.7500 (95.4861) lr 1.9686e-03 eta 0:27:23
epoch [14/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.011) loss 0.4097 (0.2676) acc 93.7500 (95.3125) lr 1.9686e-03 eta 0:27:14
epoch [14/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.010) loss 0.0527 (0.2607) acc 96.8750 (95.2841) lr 1.9686e-03 eta 0:27:07
epoch [14/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.3403 (0.2613) acc 93.7500 (95.2083) lr 1.9686e-03 eta 0:27:00
epoch [14/50] batch [65/180] time 0.238 (0.245) data 0.000 (0.008) loss 0.0953 (0.2536) acc 96.8750 (95.0962) lr 1.9686e-03 eta 0:26:55
epoch [14/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.008) loss 0.3608 (0.2551) acc 93.7500 (95.0000) lr 1.9686e-03 eta 0:26:50
epoch [14/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.1055 (0.2625) acc 93.7500 (94.9167) lr 1.9686e-03 eta 0:26:46
epoch [14/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 1.1845 (0.2836) acc 81.2500 (94.6484) lr 1.9686e-03 eta 0:26:42
epoch [14/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0235 (0.2946) acc 100.0000 (94.3750) lr 1.9686e-03 eta 0:26:38
epoch [14/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0391 (0.2913) acc 100.0000 (94.5486) lr 1.9686e-03 eta 0:26:35
epoch [14/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1414 (0.2797) acc 93.7500 (94.6711) lr 1.9686e-03 eta 0:26:32
epoch [14/50] batch [100/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0698 (0.2728) acc 93.7500 (94.7500) lr 1.9686e-03 eta 0:26:29
epoch [14/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1422 (0.2695) acc 93.7500 (94.7024) lr 1.9686e-03 eta 0:26:26
epoch [14/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.5625 (0.2713) acc 90.6250 (94.6307) lr 1.9686e-03 eta 0:26:23
epoch [14/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.2005 (0.2705) acc 90.6250 (94.5380) lr 1.9686e-03 eta 0:26:21
epoch [14/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.005) loss 0.0466 (0.2712) acc 96.8750 (94.4271) lr 1.9686e-03 eta 0:26:18
epoch [14/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1138 (0.2678) acc 96.8750 (94.4000) lr 1.9686e-03 eta 0:26:16
epoch [14/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4609 (0.2708) acc 93.7500 (94.4231) lr 1.9686e-03 eta 0:26:14
epoch [14/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4241 (0.2693) acc 96.8750 (94.4907) lr 1.9686e-03 eta 0:26:12
epoch [14/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0011 (0.2650) acc 100.0000 (94.5312) lr 1.9686e-03 eta 0:26:10
epoch [14/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.5127 (0.2748) acc 93.7500 (94.4612) lr 1.9686e-03 eta 0:26:08
epoch [14/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.2542 (0.2767) acc 93.7500 (94.4167) lr 1.9686e-03 eta 0:26:06
epoch [14/50] batch [155/180] time 0.237 (0.240) data 0.000 (0.004) loss 0.2172 (0.2754) acc 93.7500 (94.3750) lr 1.9686e-03 eta 0:26:04
epoch [14/50] batch [160/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1207 (0.2728) acc 90.6250 (94.2969) lr 1.9686e-03 eta 0:26:02
epoch [14/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0046 (0.2698) acc 100.0000 (94.3371) lr 1.9686e-03 eta 0:26:00
epoch [14/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.6592 (0.2722) acc 87.5000 (94.2647) lr 1.9686e-03 eta 0:25:58
epoch [14/50] batch [175/180] time 0.236 (0.240) data 0.000 (0.003) loss 1.1743 (0.2770) acc 90.6250 (94.3214) lr 1.9686e-03 eta 0:25:57
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [14/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.8247 (0.2772) acc 87.5000 (94.2882) lr 1.9511e-03 eta 0:25:55
在 *val* 集上测试
=> result
* total: 824
* correct: 763
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 88.8%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 3	acc: 42.9%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 7	acc: 63.6%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.3%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [15/50] batch [5/180] time 0.237 (0.336) data 0.000 (0.098) loss 0.1328 (0.2693) acc 96.8750 (96.2500) lr 1.9511e-03 eta 0:36:15
epoch [15/50] batch [10/180] time 0.237 (0.287) data 0.000 (0.049) loss 0.2822 (0.2271) acc 84.3750 (94.0625) lr 1.9511e-03 eta 0:30:53
epoch [15/50] batch [15/180] time 0.238 (0.270) data 0.000 (0.033) loss 0.1894 (0.1921) acc 90.6250 (94.7917) lr 1.9511e-03 eta 0:29:06
epoch [15/50] batch [20/180] time 0.237 (0.262) data 0.000 (0.025) loss 0.3321 (0.2265) acc 93.7500 (94.3750) lr 1.9511e-03 eta 0:28:12
epoch [15/50] batch [25/180] time 0.237 (0.257) data 0.000 (0.020) loss 0.5737 (0.2247) acc 87.5000 (94.5000) lr 1.9511e-03 eta 0:27:38
epoch [15/50] batch [30/180] time 0.238 (0.254) data 0.000 (0.016) loss 0.1779 (0.2232) acc 90.6250 (94.5833) lr 1.9511e-03 eta 0:27:16
epoch [15/50] batch [35/180] time 0.238 (0.251) data 0.000 (0.014) loss 0.4562 (0.2336) acc 90.6250 (94.1964) lr 1.9511e-03 eta 0:27:00
epoch [15/50] batch [40/180] time 0.238 (0.250) data 0.000 (0.012) loss 0.0344 (0.2262) acc 96.8750 (94.4531) lr 1.9511e-03 eta 0:26:47
epoch [15/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0891 (0.2165) acc 93.7500 (94.3750) lr 1.9511e-03 eta 0:26:37
epoch [15/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.0079 (0.2154) acc 100.0000 (94.3750) lr 1.9511e-03 eta 0:26:29
epoch [15/50] batch [55/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.0146 (0.2129) acc 100.0000 (94.5455) lr 1.9511e-03 eta 0:26:22
epoch [15/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.1310 (0.2096) acc 93.7500 (94.5312) lr 1.9511e-03 eta 0:26:16
epoch [15/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.9957 (0.2294) acc 90.6250 (94.4231) lr 1.9511e-03 eta 0:26:11
epoch [15/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.6449 (0.2495) acc 90.6250 (94.2411) lr 1.9511e-03 eta 0:26:06
epoch [15/50] batch [75/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.4008 (0.2509) acc 93.7500 (94.2500) lr 1.9511e-03 eta 0:26:02
epoch [15/50] batch [80/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2053 (0.2448) acc 93.7500 (94.2188) lr 1.9511e-03 eta 0:25:58
epoch [15/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1626 (0.2411) acc 96.8750 (94.3015) lr 1.9511e-03 eta 0:25:54
epoch [15/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.7494 (0.2476) acc 93.7500 (94.2014) lr 1.9511e-03 eta 0:25:51
epoch [15/50] batch [95/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.2074 (0.2431) acc 96.8750 (94.2763) lr 1.9511e-03 eta 0:25:48
epoch [15/50] batch [100/180] time 0.237 (0.242) data 0.000 (0.005) loss 1.3701 (0.2547) acc 87.5000 (94.2812) lr 1.9511e-03 eta 0:25:45
epoch [15/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.2397 (0.2527) acc 93.7500 (94.3155) lr 1.9511e-03 eta 0:25:42
epoch [15/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.2654 (0.2491) acc 96.8750 (94.4602) lr 1.9511e-03 eta 0:25:39
epoch [15/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.4533 (0.2492) acc 90.6250 (94.4293) lr 1.9511e-03 eta 0:25:37
epoch [15/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.9158 (0.2537) acc 93.7500 (94.4531) lr 1.9511e-03 eta 0:25:35
epoch [15/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1012 (0.2488) acc 96.8750 (94.5250) lr 1.9511e-03 eta 0:25:32
epoch [15/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0271 (0.2521) acc 96.8750 (94.5192) lr 1.9511e-03 eta 0:25:30
epoch [15/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0702 (0.2522) acc 96.8750 (94.5602) lr 1.9511e-03 eta 0:25:28
epoch [15/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1694 (0.2578) acc 90.6250 (94.5089) lr 1.9511e-03 eta 0:25:26
epoch [15/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0379 (0.2571) acc 96.8750 (94.5259) lr 1.9511e-03 eta 0:25:24
epoch [15/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.3714 (0.2530) acc 93.7500 (94.5833) lr 1.9511e-03 eta 0:25:22
epoch [15/50] batch [155/180] time 0.237 (0.240) data 0.000 (0.003) loss 1.2948 (0.2578) acc 90.6250 (94.5161) lr 1.9511e-03 eta 0:25:20
epoch [15/50] batch [160/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2374 (0.2597) acc 93.7500 (94.4531) lr 1.9511e-03 eta 0:25:18
epoch [15/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.3115 (0.2575) acc 93.7500 (94.4508) lr 1.9511e-03 eta 0:25:17
epoch [15/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0070 (0.2562) acc 100.0000 (94.4118) lr 1.9511e-03 eta 0:25:15
epoch [15/50] batch [175/180] time 0.236 (0.240) data 0.000 (0.003) loss 0.0112 (0.2508) acc 100.0000 (94.4821) lr 1.9511e-03 eta 0:25:13
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [15/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2868 (0.2574) acc 93.7500 (94.4444) lr 1.0000e-05 eta 0:25:11
在 *val* 集上测试
=> result
* total: 824
* correct: 764
* accuracy: 92.7%
* error: 7.3%
* macro_f1: 88.7%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 2	acc: 33.3%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 10	acc: 90.9%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 1	acc: 16.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.2%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model.pth.tar-15
epoch [16/50] batch [5/180] time 0.237 (0.347) data 0.000 (0.109) loss 0.0182 (0.0544) acc 100.0000 (97.5000) lr 1.0000e-05 eta 0:36:22
epoch [16/50] batch [10/180] time 0.238 (0.292) data 0.000 (0.055) loss 0.0853 (0.1778) acc 93.7500 (95.9375) lr 1.0000e-05 eta 0:30:36
epoch [16/50] batch [15/180] time 0.237 (0.274) data 0.000 (0.036) loss 0.0342 (0.2099) acc 96.8750 (96.0417) lr 1.0000e-05 eta 0:28:40
epoch [16/50] batch [20/180] time 0.237 (0.265) data 0.000 (0.027) loss 0.0253 (0.1842) acc 100.0000 (96.4062) lr 1.0000e-05 eta 0:27:42
epoch [16/50] batch [25/180] time 0.237 (0.259) data 0.000 (0.022) loss 0.0924 (0.2031) acc 96.8750 (96.0000) lr 1.0000e-05 eta 0:27:06
epoch [16/50] batch [30/180] time 0.238 (0.256) data 0.000 (0.018) loss 0.2314 (0.2298) acc 87.5000 (95.2083) lr 1.0000e-05 eta 0:26:42
epoch [16/50] batch [35/180] time 0.238 (0.253) data 0.000 (0.016) loss 0.7157 (0.2601) acc 90.6250 (94.9107) lr 1.0000e-05 eta 0:26:25
epoch [16/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.0119 (0.2501) acc 100.0000 (94.8438) lr 1.0000e-05 eta 0:26:11
epoch [16/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.012) loss 0.0007 (0.2441) acc 100.0000 (94.8611) lr 1.0000e-05 eta 0:26:00
epoch [16/50] batch [50/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0761 (0.2428) acc 93.7500 (94.8750) lr 1.0000e-05 eta 0:25:52
epoch [16/50] batch [55/180] time 0.238 (0.247) data 0.000 (0.010) loss 0.5907 (0.2325) acc 90.6250 (95.1705) lr 1.0000e-05 eta 0:25:44
epoch [16/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.009) loss 0.1255 (0.2317) acc 96.8750 (95.3125) lr 1.0000e-05 eta 0:25:38
epoch [16/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.1345 (0.2311) acc 96.8750 (95.2885) lr 1.0000e-05 eta 0:25:32
epoch [16/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1401 (0.2255) acc 93.7500 (95.3125) lr 1.0000e-05 eta 0:25:27
epoch [16/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.0294 (0.2210) acc 96.8750 (95.3333) lr 1.0000e-05 eta 0:25:23
epoch [16/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.6402 (0.2242) acc 90.6250 (95.2344) lr 1.0000e-05 eta 0:25:19
epoch [16/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0454 (0.2283) acc 96.8750 (94.9632) lr 1.0000e-05 eta 0:25:15
epoch [16/50] batch [90/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.1942 (0.2251) acc 93.7500 (94.8958) lr 1.0000e-05 eta 0:25:11
epoch [16/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.3333 (0.2301) acc 90.6250 (94.9342) lr 1.0000e-05 eta 0:25:08
epoch [16/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.6193 (0.2338) acc 93.7500 (94.8750) lr 1.0000e-05 eta 0:25:05
epoch [16/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.7499 (0.2407) acc 93.7500 (94.9107) lr 1.0000e-05 eta 0:25:03
epoch [16/50] batch [110/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.1718 (0.2375) acc 96.8750 (94.9148) lr 1.0000e-05 eta 0:25:00
epoch [16/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.1866 (0.2369) acc 90.6250 (94.8641) lr 1.0000e-05 eta 0:24:58
epoch [16/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0213 (0.2347) acc 100.0000 (94.8958) lr 1.0000e-05 eta 0:24:55
epoch [16/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1310 (0.2388) acc 96.8750 (94.9000) lr 1.0000e-05 eta 0:24:53
epoch [16/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0245 (0.2329) acc 100.0000 (94.9760) lr 1.0000e-05 eta 0:24:50
epoch [16/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4740 (0.2393) acc 93.7500 (94.9537) lr 1.0000e-05 eta 0:24:48
epoch [16/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0199 (0.2354) acc 100.0000 (95.0223) lr 1.0000e-05 eta 0:24:46
epoch [16/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0667 (0.2365) acc 96.8750 (94.9784) lr 1.0000e-05 eta 0:24:44
epoch [16/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0757 (0.2309) acc 96.8750 (95.0625) lr 1.0000e-05 eta 0:24:42
epoch [16/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0151 (0.2310) acc 100.0000 (95.0806) lr 1.0000e-05 eta 0:24:40
epoch [16/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.8389 (0.2458) acc 93.7500 (94.9805) lr 1.0000e-05 eta 0:24:38
epoch [16/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.2429 (0.2427) acc 87.5000 (94.9621) lr 1.0000e-05 eta 0:24:36
epoch [16/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.4493 (0.2423) acc 90.6250 (94.9449) lr 1.0000e-05 eta 0:24:34
epoch [16/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1372 (0.2405) acc 93.7500 (94.9107) lr 1.0000e-05 eta 0:24:33
Adjusting learning rate of group 0 to 1.9511e-03.
epoch [16/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2725 (0.2396) acc 90.6250 (94.9132) lr 1.9511e-03 eta 0:24:31
在 *val* 集上测试
=> result
* total: 824
* correct: 762
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 88.5%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 2	acc: 33.3%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 1	acc: 16.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.0%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [17/50] batch [5/180] time 0.238 (0.336) data 0.000 (0.098) loss 0.1736 (0.1016) acc 93.7500 (95.6250) lr 1.9511e-03 eta 0:34:14
epoch [17/50] batch [10/180] time 0.237 (0.287) data 0.000 (0.049) loss 0.1524 (0.0967) acc 90.6250 (95.6250) lr 1.9511e-03 eta 0:29:11
epoch [17/50] batch [15/180] time 0.238 (0.270) data 0.000 (0.033) loss 0.0154 (0.0957) acc 100.0000 (96.0417) lr 1.9511e-03 eta 0:27:29
epoch [17/50] batch [20/180] time 0.237 (0.262) data 0.000 (0.025) loss 0.0232 (0.1077) acc 100.0000 (96.2500) lr 1.9511e-03 eta 0:26:37
epoch [17/50] batch [25/180] time 0.237 (0.257) data 0.000 (0.020) loss 0.3846 (0.1368) acc 96.8750 (96.3750) lr 1.9511e-03 eta 0:26:06
epoch [17/50] batch [30/180] time 0.237 (0.254) data 0.000 (0.016) loss 0.2425 (0.1388) acc 96.8750 (96.4583) lr 1.9511e-03 eta 0:25:45
epoch [17/50] batch [35/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.0441 (0.1899) acc 96.8750 (96.1607) lr 1.9511e-03 eta 0:25:29
epoch [17/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.012) loss 0.0017 (0.1904) acc 100.0000 (96.0938) lr 1.9511e-03 eta 0:25:17
epoch [17/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0934 (0.1836) acc 93.7500 (96.1111) lr 1.9511e-03 eta 0:25:08
epoch [17/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.0772 (0.1928) acc 93.7500 (95.8750) lr 1.9511e-03 eta 0:25:00
epoch [17/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2474 (0.2034) acc 93.7500 (95.7386) lr 1.9511e-03 eta 0:24:53
epoch [17/50] batch [60/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.3057 (0.1977) acc 90.6250 (95.7812) lr 1.9511e-03 eta 0:24:47
epoch [17/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.7951 (0.2031) acc 90.6250 (95.7692) lr 1.9511e-03 eta 0:24:42
epoch [17/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0386 (0.2084) acc 96.8750 (95.6696) lr 1.9511e-03 eta 0:24:38
epoch [17/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0344 (0.2071) acc 100.0000 (95.7083) lr 1.9511e-03 eta 0:24:33
epoch [17/50] batch [80/180] time 0.238 (0.243) data 0.000 (0.006) loss 1.0533 (0.2160) acc 93.7500 (95.7422) lr 1.9511e-03 eta 0:24:30
epoch [17/50] batch [85/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.6662 (0.2247) acc 87.5000 (95.5147) lr 1.9511e-03 eta 0:24:27
epoch [17/50] batch [90/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.0124 (0.2237) acc 100.0000 (95.3819) lr 1.9511e-03 eta 0:24:24
epoch [17/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.1471 (0.2225) acc 93.7500 (95.3618) lr 1.9511e-03 eta 0:24:21
epoch [17/50] batch [100/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0344 (0.2245) acc 96.8750 (95.3125) lr 1.9511e-03 eta 0:24:18
epoch [17/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.4201 (0.2334) acc 90.6250 (95.2083) lr 1.9511e-03 eta 0:24:16
epoch [17/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.9212 (0.2436) acc 84.3750 (95.1420) lr 1.9511e-03 eta 0:24:13
epoch [17/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.3761 (0.2451) acc 87.5000 (95.1087) lr 1.9511e-03 eta 0:24:11
epoch [17/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.6028 (0.2428) acc 90.6250 (95.1302) lr 1.9511e-03 eta 0:24:09
epoch [17/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1789 (0.2402) acc 93.7500 (95.0750) lr 1.9511e-03 eta 0:24:06
epoch [17/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0898 (0.2380) acc 96.8750 (95.0721) lr 1.9511e-03 eta 0:24:04
epoch [17/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1995 (0.2363) acc 93.7500 (95.0231) lr 1.9511e-03 eta 0:24:02
epoch [17/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.7216 (0.2372) acc 84.3750 (94.9330) lr 1.9511e-03 eta 0:24:00
epoch [17/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.3552 (0.2372) acc 93.7500 (94.8491) lr 1.9511e-03 eta 0:23:58
epoch [17/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4451 (0.2485) acc 90.6250 (94.7708) lr 1.9511e-03 eta 0:23:56
epoch [17/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.4798 (0.2545) acc 90.6250 (94.7379) lr 1.9511e-03 eta 0:23:55
epoch [17/50] batch [160/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.0549 (0.2555) acc 96.8750 (94.6680) lr 1.9511e-03 eta 0:23:53
epoch [17/50] batch [165/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.3481 (0.2535) acc 90.6250 (94.6591) lr 1.9511e-03 eta 0:23:51
epoch [17/50] batch [170/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.3099 (0.2518) acc 96.8750 (94.6507) lr 1.9511e-03 eta 0:23:49
epoch [17/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1106 (0.2476) acc 96.8750 (94.6964) lr 1.9511e-03 eta 0:23:48
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [17/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1010 (0.2447) acc 96.8750 (94.7396) lr 1.9298e-03 eta 0:23:46
在 *val* 集上测试
=> result
* total: 824
* correct: 771
* accuracy: 93.6%
* error: 6.4%
* macro_f1: 90.1%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 4	acc: 66.7%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 7	acc: 87.5%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 8	acc: 72.7%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 90.5%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [18/50] batch [5/180] time 0.237 (0.334) data 0.000 (0.094) loss 0.3428 (0.3345) acc 96.8750 (93.7500) lr 1.9298e-03 eta 0:33:00
epoch [18/50] batch [10/180] time 0.237 (0.286) data 0.000 (0.047) loss 0.0224 (0.3735) acc 100.0000 (94.3750) lr 1.9298e-03 eta 0:28:13
epoch [18/50] batch [15/180] time 0.238 (0.270) data 0.000 (0.031) loss 0.1129 (0.3240) acc 93.7500 (94.5833) lr 1.9298e-03 eta 0:26:36
epoch [18/50] batch [20/180] time 0.237 (0.261) data 0.000 (0.024) loss 0.1619 (0.3353) acc 93.7500 (93.7500) lr 1.9298e-03 eta 0:25:47
epoch [18/50] batch [25/180] time 0.237 (0.257) data 0.000 (0.019) loss 0.0441 (0.3124) acc 96.8750 (93.5000) lr 1.9298e-03 eta 0:25:18
epoch [18/50] batch [30/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.1895 (0.3015) acc 93.7500 (94.0625) lr 1.9298e-03 eta 0:24:57
epoch [18/50] batch [35/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.2145 (0.2925) acc 96.8750 (94.2857) lr 1.9298e-03 eta 0:24:42
epoch [18/50] batch [40/180] time 0.238 (0.249) data 0.000 (0.012) loss 0.2850 (0.2700) acc 96.8750 (94.6094) lr 1.9298e-03 eta 0:24:31
epoch [18/50] batch [45/180] time 0.238 (0.248) data 0.000 (0.011) loss 0.2087 (0.2617) acc 87.5000 (94.3056) lr 1.9298e-03 eta 0:24:22
epoch [18/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.1434 (0.2477) acc 93.7500 (94.4375) lr 1.9298e-03 eta 0:24:14
epoch [18/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2000 (0.2604) acc 96.8750 (94.2614) lr 1.9298e-03 eta 0:24:08
epoch [18/50] batch [60/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.6832 (0.2561) acc 84.3750 (94.2708) lr 1.9298e-03 eta 0:24:03
epoch [18/50] batch [65/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.2893 (0.2667) acc 93.7500 (94.3269) lr 1.9298e-03 eta 0:23:58
epoch [18/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0084 (0.2637) acc 100.0000 (94.4196) lr 1.9298e-03 eta 0:23:53
epoch [18/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.1146 (0.2623) acc 96.8750 (94.4167) lr 1.9298e-03 eta 0:23:50
epoch [18/50] batch [80/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.1373 (0.2530) acc 90.6250 (94.5703) lr 1.9298e-03 eta 0:23:46
epoch [18/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2833 (0.2690) acc 93.7500 (94.3750) lr 1.9298e-03 eta 0:23:43
epoch [18/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.2810 (0.2642) acc 96.8750 (94.4444) lr 1.9298e-03 eta 0:23:40
epoch [18/50] batch [95/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0401 (0.2575) acc 100.0000 (94.4408) lr 1.9298e-03 eta 0:23:37
epoch [18/50] batch [100/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2492 (0.2517) acc 90.6250 (94.4688) lr 1.9298e-03 eta 0:23:34
epoch [18/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.1646 (0.2464) acc 96.8750 (94.5833) lr 1.9298e-03 eta 0:23:32
epoch [18/50] batch [110/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.2244 (0.2445) acc 93.7500 (94.6023) lr 1.9298e-03 eta 0:23:29
epoch [18/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0306 (0.2537) acc 100.0000 (94.6467) lr 1.9298e-03 eta 0:23:27
epoch [18/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.6773 (0.2545) acc 93.7500 (94.6875) lr 1.9298e-03 eta 0:23:25
epoch [18/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0601 (0.2577) acc 96.8750 (94.6000) lr 1.9298e-03 eta 0:23:23
epoch [18/50] batch [130/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0923 (0.2568) acc 93.7500 (94.5913) lr 1.9298e-03 eta 0:23:21
epoch [18/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.6764 (0.2569) acc 87.5000 (94.5370) lr 1.9298e-03 eta 0:23:19
epoch [18/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0737 (0.2524) acc 96.8750 (94.4866) lr 1.9298e-03 eta 0:23:17
epoch [18/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0390 (0.2482) acc 100.0000 (94.5690) lr 1.9298e-03 eta 0:23:15
epoch [18/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0442 (0.2424) acc 96.8750 (94.7083) lr 1.9298e-03 eta 0:23:14
epoch [18/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.1265 (0.2461) acc 96.8750 (94.6573) lr 1.9298e-03 eta 0:23:12
epoch [18/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0272 (0.2441) acc 100.0000 (94.6875) lr 1.9298e-03 eta 0:23:10
epoch [18/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0389 (0.2406) acc 96.8750 (94.7348) lr 1.9298e-03 eta 0:23:08
epoch [18/50] batch [170/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.0341 (0.2356) acc 100.0000 (94.8162) lr 1.9298e-03 eta 0:23:07
epoch [18/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0339 (0.2334) acc 96.8750 (94.7857) lr 1.9298e-03 eta 0:23:05
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [18/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.5009 (0.2376) acc 90.6250 (94.7743) lr 1.0000e-05 eta 0:23:03
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.3%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 1	acc: 16.7%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 7	acc: 87.5%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 3	acc: 75.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.7%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [19/50] batch [5/180] time 0.237 (0.331) data 0.000 (0.093) loss 0.0944 (0.2477) acc 93.7500 (92.5000) lr 1.0000e-05 eta 0:31:44
epoch [19/50] batch [10/180] time 0.237 (0.284) data 0.000 (0.047) loss 0.0055 (0.2137) acc 100.0000 (94.0625) lr 1.0000e-05 eta 0:27:12
epoch [19/50] batch [15/180] time 0.238 (0.269) data 0.000 (0.031) loss 0.0562 (0.1823) acc 96.8750 (94.5833) lr 1.0000e-05 eta 0:25:43
epoch [19/50] batch [20/180] time 0.238 (0.261) data 0.000 (0.023) loss 0.1802 (0.1749) acc 87.5000 (94.5312) lr 1.0000e-05 eta 0:24:57
epoch [19/50] batch [25/180] time 0.237 (0.256) data 0.000 (0.019) loss 0.0552 (0.1867) acc 96.8750 (94.8750) lr 1.0000e-05 eta 0:24:29
epoch [19/50] batch [30/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.0766 (0.1626) acc 96.8750 (95.4167) lr 1.0000e-05 eta 0:24:09
epoch [19/50] batch [35/180] time 0.239 (0.251) data 0.000 (0.013) loss 0.4713 (0.1687) acc 96.8750 (95.4464) lr 1.0000e-05 eta 0:23:55
epoch [19/50] batch [40/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.0050 (0.1919) acc 100.0000 (95.3906) lr 1.0000e-05 eta 0:23:45
epoch [19/50] batch [45/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.2647 (0.2120) acc 96.8750 (95.3472) lr 1.0000e-05 eta 0:23:36
epoch [19/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.009) loss 0.2399 (0.2240) acc 93.7500 (95.1875) lr 1.0000e-05 eta 0:23:29
epoch [19/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.0483 (0.2205) acc 96.8750 (95.3409) lr 1.0000e-05 eta 0:23:23
epoch [19/50] batch [60/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.3020 (0.2191) acc 93.7500 (95.2604) lr 1.0000e-05 eta 0:23:17
epoch [19/50] batch [65/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.6264 (0.2191) acc 96.8750 (95.3365) lr 1.0000e-05 eta 0:23:13
epoch [19/50] batch [70/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.0370 (0.2165) acc 100.0000 (95.4464) lr 1.0000e-05 eta 0:23:09
epoch [19/50] batch [75/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.4347 (0.2267) acc 93.7500 (95.3750) lr 1.0000e-05 eta 0:23:05
epoch [19/50] batch [80/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.3518 (0.2201) acc 96.8750 (95.4688) lr 1.0000e-05 eta 0:23:02
epoch [19/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0681 (0.2133) acc 96.8750 (95.4779) lr 1.0000e-05 eta 0:22:59
epoch [19/50] batch [90/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.5629 (0.2154) acc 96.8750 (95.5208) lr 1.0000e-05 eta 0:22:56
epoch [19/50] batch [95/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.1423 (0.2085) acc 96.8750 (95.6250) lr 1.0000e-05 eta 0:22:53
epoch [19/50] batch [100/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.4691 (0.2231) acc 93.7500 (95.4062) lr 1.0000e-05 eta 0:22:51
epoch [19/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.3134 (0.2222) acc 93.7500 (95.4464) lr 1.0000e-05 eta 0:22:48
epoch [19/50] batch [110/180] time 0.239 (0.242) data 0.000 (0.004) loss 0.5924 (0.2307) acc 93.7500 (95.3409) lr 1.0000e-05 eta 0:22:46
epoch [19/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.7311 (0.2280) acc 90.6250 (95.4076) lr 1.0000e-05 eta 0:22:44
epoch [19/50] batch [120/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1025 (0.2275) acc 96.8750 (95.3125) lr 1.0000e-05 eta 0:22:42
epoch [19/50] batch [125/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0052 (0.2194) acc 100.0000 (95.4500) lr 1.0000e-05 eta 0:22:40
epoch [19/50] batch [130/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1057 (0.2176) acc 96.8750 (95.4808) lr 1.0000e-05 eta 0:22:38
epoch [19/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.2877 (0.2266) acc 90.6250 (95.3935) lr 1.0000e-05 eta 0:22:36
epoch [19/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1525 (0.2302) acc 96.8750 (95.3348) lr 1.0000e-05 eta 0:22:34
epoch [19/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.5366 (0.2352) acc 93.7500 (95.2586) lr 1.0000e-05 eta 0:22:32
epoch [19/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.5073 (0.2387) acc 90.6250 (95.2083) lr 1.0000e-05 eta 0:22:30
epoch [19/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0955 (0.2341) acc 93.7500 (95.2218) lr 1.0000e-05 eta 0:22:28
epoch [19/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0066 (0.2387) acc 100.0000 (95.1953) lr 1.0000e-05 eta 0:22:27
epoch [19/50] batch [165/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.2042 (0.2351) acc 90.6250 (95.2462) lr 1.0000e-05 eta 0:22:25
epoch [19/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1717 (0.2366) acc 96.8750 (95.2757) lr 1.0000e-05 eta 0:22:23
epoch [19/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1047 (0.2321) acc 96.8750 (95.3393) lr 1.0000e-05 eta 0:22:22
Adjusting learning rate of group 0 to 1.9298e-03.
epoch [19/50] batch [180/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.0119 (0.2275) acc 100.0000 (95.3819) lr 1.9298e-03 eta 0:22:20
在 *val* 集上测试
=> result
* total: 824
* correct: 766
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 89.1%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 2	acc: 33.3%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 9	acc: 81.8%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 4	acc: 57.1%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 2	acc: 33.3%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.5%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [20/50] batch [5/180] time 0.238 (0.347) data 0.000 (0.108) loss 0.3711 (0.2509) acc 90.6250 (95.0000) lr 1.9298e-03 eta 0:32:12
epoch [20/50] batch [10/180] time 0.237 (0.292) data 0.000 (0.054) loss 0.0376 (0.2438) acc 96.8750 (95.0000) lr 1.9298e-03 eta 0:27:07
epoch [20/50] batch [15/180] time 0.238 (0.274) data 0.000 (0.036) loss 0.5436 (0.2347) acc 93.7500 (95.6250) lr 1.9298e-03 eta 0:25:25
epoch [20/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.027) loss 0.3544 (0.2040) acc 96.8750 (96.0938) lr 1.9298e-03 eta 0:24:33
epoch [20/50] batch [25/180] time 0.238 (0.259) data 0.000 (0.022) loss 0.2646 (0.2047) acc 93.7500 (95.6250) lr 1.9298e-03 eta 0:24:01
epoch [20/50] batch [30/180] time 0.238 (0.256) data 0.000 (0.018) loss 0.8116 (0.2785) acc 90.6250 (94.2708) lr 1.9298e-03 eta 0:23:40
epoch [20/50] batch [35/180] time 0.238 (0.253) data 0.000 (0.016) loss 0.1152 (0.2605) acc 93.7500 (94.1964) lr 1.9298e-03 eta 0:23:24
epoch [20/50] batch [40/180] time 0.238 (0.251) data 0.000 (0.014) loss 0.0538 (0.2404) acc 100.0000 (94.5312) lr 1.9298e-03 eta 0:23:12
epoch [20/50] batch [45/180] time 0.238 (0.250) data 0.000 (0.012) loss 0.0090 (0.2195) acc 100.0000 (95.0000) lr 1.9298e-03 eta 0:23:02
epoch [20/50] batch [50/180] time 0.237 (0.249) data 0.000 (0.011) loss 0.6780 (0.2248) acc 93.7500 (95.0625) lr 1.9298e-03 eta 0:22:54
epoch [20/50] batch [55/180] time 0.238 (0.248) data 0.000 (0.010) loss 0.2132 (0.2195) acc 93.7500 (94.8864) lr 1.9298e-03 eta 0:22:47
epoch [20/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.009) loss 0.1444 (0.2145) acc 96.8750 (95.0000) lr 1.9298e-03 eta 0:22:41
epoch [20/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0337 (0.2218) acc 100.0000 (95.0000) lr 1.9298e-03 eta 0:22:36
epoch [20/50] batch [70/180] time 0.238 (0.245) data 0.000 (0.008) loss 0.1371 (0.2160) acc 96.8750 (95.0000) lr 1.9298e-03 eta 0:22:32
epoch [20/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.1896 (0.2108) acc 90.6250 (94.9583) lr 1.9298e-03 eta 0:22:27
epoch [20/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.3380 (0.2089) acc 93.7500 (95.0391) lr 1.9298e-03 eta 0:22:24
epoch [20/50] batch [85/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.0369 (0.2078) acc 100.0000 (95.1103) lr 1.9298e-03 eta 0:22:20
epoch [20/50] batch [90/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.1327 (0.2273) acc 90.6250 (94.9653) lr 1.9298e-03 eta 0:22:17
epoch [20/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1398 (0.2313) acc 93.7500 (94.9671) lr 1.9298e-03 eta 0:22:14
epoch [20/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1755 (0.2272) acc 96.8750 (94.8750) lr 1.9298e-03 eta 0:22:11
epoch [20/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0073 (0.2247) acc 100.0000 (94.9702) lr 1.9298e-03 eta 0:22:09
epoch [20/50] batch [110/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.1845 (0.2221) acc 96.8750 (94.9148) lr 1.9298e-03 eta 0:22:06
epoch [20/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.4374 (0.2201) acc 90.6250 (94.8913) lr 1.9298e-03 eta 0:22:04
epoch [20/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0422 (0.2129) acc 96.8750 (95.0260) lr 1.9298e-03 eta 0:22:02
epoch [20/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.1880 (0.2082) acc 96.8750 (95.1000) lr 1.9298e-03 eta 0:21:59
epoch [20/50] batch [130/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.7077 (0.2112) acc 87.5000 (95.0000) lr 1.9298e-03 eta 0:21:57
epoch [20/50] batch [135/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.6270 (0.2179) acc 93.7500 (95.0000) lr 1.9298e-03 eta 0:21:55
epoch [20/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.2401 (0.2213) acc 93.7500 (94.9107) lr 1.9298e-03 eta 0:21:53
epoch [20/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1529 (0.2199) acc 93.7500 (94.9353) lr 1.9298e-03 eta 0:21:51
epoch [20/50] batch [150/180] time 0.238 (0.241) data 0.001 (0.004) loss 0.1070 (0.2153) acc 96.8750 (94.9792) lr 1.9298e-03 eta 0:21:49
epoch [20/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.7062 (0.2194) acc 84.3750 (94.8992) lr 1.9298e-03 eta 0:21:47
epoch [20/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1768 (0.2175) acc 90.6250 (94.8828) lr 1.9298e-03 eta 0:21:46
epoch [20/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.9884 (0.2200) acc 87.5000 (94.8485) lr 1.9298e-03 eta 0:21:44
epoch [20/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0223 (0.2175) acc 100.0000 (94.9081) lr 1.9298e-03 eta 0:21:42
epoch [20/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0437 (0.2202) acc 96.8750 (94.9107) lr 1.9298e-03 eta 0:21:40
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [20/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.3207 (0.2199) acc 87.5000 (94.8611) lr 1.9048e-03 eta 0:21:39
在 *val* 集上测试
=> result
* total: 824
* correct: 763
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 88.3%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 4	acc: 66.7%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 8	acc: 72.7%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 6	acc: 85.7%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 0	acc: 0.0%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 8	acc: 88.9%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 88.6%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model.pth.tar-20
epoch [21/50] batch [5/180] time 0.238 (0.348) data 0.000 (0.110) loss 0.3564 (0.2513) acc 90.6250 (93.7500) lr 1.9048e-03 eta 0:31:19
epoch [21/50] batch [10/180] time 0.238 (0.293) data 0.000 (0.055) loss 0.3450 (0.1833) acc 90.6250 (94.6875) lr 1.9048e-03 eta 0:26:19
epoch [21/50] batch [15/180] time 0.238 (0.275) data 0.000 (0.037) loss 0.0677 (0.1748) acc 96.8750 (95.2083) lr 1.9048e-03 eta 0:24:38
epoch [21/50] batch [20/180] time 0.238 (0.265) data 0.000 (0.028) loss 0.3691 (0.1799) acc 90.6250 (95.3125) lr 1.9048e-03 eta 0:23:47
epoch [21/50] batch [25/180] time 0.238 (0.260) data 0.000 (0.022) loss 0.0394 (0.1548) acc 96.8750 (95.8750) lr 1.9048e-03 eta 0:23:16
epoch [21/50] batch [30/180] time 0.238 (0.256) data 0.000 (0.018) loss 0.5192 (0.1814) acc 90.6250 (95.7292) lr 1.9048e-03 eta 0:22:55
epoch [21/50] batch [35/180] time 0.237 (0.253) data 0.000 (0.016) loss 0.0626 (0.1920) acc 96.8750 (95.2679) lr 1.9048e-03 eta 0:22:39
epoch [21/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.0322 (0.1856) acc 100.0000 (95.3125) lr 1.9048e-03 eta 0:22:27
epoch [21/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.012) loss 0.4071 (0.1812) acc 93.7500 (95.2083) lr 1.9048e-03 eta 0:22:17
epoch [21/50] batch [50/180] time 0.237 (0.249) data 0.000 (0.011) loss 0.0610 (0.1955) acc 96.8750 (95.1250) lr 1.9048e-03 eta 0:22:10
epoch [21/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.010) loss 0.0390 (0.1994) acc 100.0000 (95.2273) lr 1.9048e-03 eta 0:22:03
epoch [21/50] batch [60/180] time 0.237 (0.247) data 0.000 (0.009) loss 0.2213 (0.2005) acc 90.6250 (95.1042) lr 1.9048e-03 eta 0:21:57
epoch [21/50] batch [65/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.0890 (0.1942) acc 96.8750 (95.2404) lr 1.9048e-03 eta 0:21:52
epoch [21/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.0266 (0.1850) acc 96.8750 (95.3571) lr 1.9048e-03 eta 0:21:48
epoch [21/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.0495 (0.1847) acc 96.8750 (95.3333) lr 1.9048e-03 eta 0:21:44
epoch [21/50] batch [80/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.6597 (0.1956) acc 93.7500 (95.3516) lr 1.9048e-03 eta 0:21:40
epoch [21/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.1263 (0.1983) acc 93.7500 (95.2574) lr 1.9048e-03 eta 0:21:37
epoch [21/50] batch [90/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.5205 (0.2019) acc 87.5000 (95.1042) lr 1.9048e-03 eta 0:21:33
epoch [21/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.8403 (0.2077) acc 96.8750 (95.1316) lr 1.9048e-03 eta 0:21:31
epoch [21/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.4833 (0.2089) acc 90.6250 (95.0625) lr 1.9048e-03 eta 0:21:28
epoch [21/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.7624 (0.2135) acc 87.5000 (95.0000) lr 1.9048e-03 eta 0:21:25
epoch [21/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0815 (0.2110) acc 93.7500 (95.0284) lr 1.9048e-03 eta 0:21:23
epoch [21/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.3255 (0.2183) acc 93.7500 (94.9185) lr 1.9048e-03 eta 0:21:20
epoch [21/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1273 (0.2233) acc 90.6250 (94.8958) lr 1.9048e-03 eta 0:21:18
epoch [21/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0933 (0.2255) acc 96.8750 (94.8500) lr 1.9048e-03 eta 0:21:16
epoch [21/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.4670 (0.2299) acc 90.6250 (94.7596) lr 1.9048e-03 eta 0:21:14
epoch [21/50] batch [135/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.4672 (0.2312) acc 93.7500 (94.7222) lr 1.9048e-03 eta 0:21:12
epoch [21/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.3945 (0.2308) acc 93.7500 (94.7098) lr 1.9048e-03 eta 0:21:10
epoch [21/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1878 (0.2270) acc 93.7500 (94.7198) lr 1.9048e-03 eta 0:21:08
epoch [21/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.2321 (0.2263) acc 96.8750 (94.7500) lr 1.9048e-03 eta 0:21:06
epoch [21/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0039 (0.2223) acc 100.0000 (94.8387) lr 1.9048e-03 eta 0:21:04
epoch [21/50] batch [160/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1655 (0.2196) acc 96.8750 (94.8633) lr 1.9048e-03 eta 0:21:02
epoch [21/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0041 (0.2170) acc 100.0000 (94.8864) lr 1.9048e-03 eta 0:21:00
epoch [21/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0042 (0.2149) acc 100.0000 (94.9081) lr 1.9048e-03 eta 0:20:59
epoch [21/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0975 (0.2110) acc 93.7500 (94.9643) lr 1.9048e-03 eta 0:20:57
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [21/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1861 (0.2117) acc 96.8750 (94.9653) lr 1.0000e-05 eta 0:20:55
在 *val* 集上测试
=> result
* total: 824
* correct: 770
* accuracy: 93.4%
* error: 6.6%
* macro_f1: 89.6%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 5	acc: 83.3%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 6	acc: 100.0%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 4	acc: 66.7%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 6	acc: 85.7%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 7	acc: 63.6%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 6	acc: 85.7%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 5	acc: 62.5%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 4	acc: 66.7%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.8%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [22/50] batch [5/180] time 0.237 (0.334) data 0.000 (0.095) loss 0.3740 (0.2280) acc 90.6250 (93.1250) lr 1.0000e-05 eta 0:29:04
epoch [22/50] batch [10/180] time 0.237 (0.286) data 0.000 (0.048) loss 0.0956 (0.1566) acc 96.8750 (95.0000) lr 1.0000e-05 eta 0:24:49
epoch [22/50] batch [15/180] time 0.237 (0.270) data 0.000 (0.032) loss 0.3343 (0.1552) acc 87.5000 (95.0000) lr 1.0000e-05 eta 0:23:24
epoch [22/50] batch [20/180] time 0.238 (0.262) data 0.000 (0.024) loss 0.0366 (0.1623) acc 100.0000 (95.1562) lr 1.0000e-05 eta 0:22:41
epoch [22/50] batch [25/180] time 0.238 (0.257) data 0.000 (0.019) loss 0.0174 (0.2166) acc 100.0000 (94.6250) lr 1.0000e-05 eta 0:22:14
epoch [22/50] batch [30/180] time 0.237 (0.254) data 0.000 (0.016) loss 0.2705 (0.2113) acc 90.6250 (94.4792) lr 1.0000e-05 eta 0:21:56
epoch [22/50] batch [35/180] time 0.238 (0.251) data 0.000 (0.014) loss 0.2831 (0.2037) acc 84.3750 (94.1964) lr 1.0000e-05 eta 0:21:43
epoch [22/50] batch [40/180] time 0.238 (0.250) data 0.000 (0.012) loss 0.8815 (0.2046) acc 93.7500 (94.5312) lr 1.0000e-05 eta 0:21:33
epoch [22/50] batch [45/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0381 (0.2016) acc 96.8750 (94.5833) lr 1.0000e-05 eta 0:21:24
epoch [22/50] batch [50/180] time 0.238 (0.247) data 0.000 (0.010) loss 0.0924 (0.1992) acc 96.8750 (94.6250) lr 1.0000e-05 eta 0:21:17
epoch [22/50] batch [55/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.3546 (0.2135) acc 90.6250 (94.3750) lr 1.0000e-05 eta 0:21:12
epoch [22/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0215 (0.2173) acc 100.0000 (94.5833) lr 1.0000e-05 eta 0:21:07
epoch [22/50] batch [65/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.3687 (0.2158) acc 90.6250 (94.6154) lr 1.0000e-05 eta 0:21:02
epoch [22/50] batch [70/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.4760 (0.2108) acc 90.6250 (94.6875) lr 1.0000e-05 eta 0:20:58
epoch [22/50] batch [75/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.0782 (0.2066) acc 96.8750 (94.8750) lr 1.0000e-05 eta 0:20:55
epoch [22/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.3962 (0.2103) acc 87.5000 (94.6875) lr 1.0000e-05 eta 0:20:52
epoch [22/50] batch [85/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.2835 (0.2157) acc 93.7500 (94.5956) lr 1.0000e-05 eta 0:20:48
epoch [22/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.1465 (0.2136) acc 90.6250 (94.6181) lr 1.0000e-05 eta 0:20:46
epoch [22/50] batch [95/180] time 0.238 (0.243) data 0.000 (0.005) loss 0.1864 (0.2080) acc 93.7500 (94.7039) lr 1.0000e-05 eta 0:20:43
epoch [22/50] batch [100/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2690 (0.2120) acc 90.6250 (94.6250) lr 1.0000e-05 eta 0:20:41
epoch [22/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0833 (0.2129) acc 96.8750 (94.6131) lr 1.0000e-05 eta 0:20:38
epoch [22/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0933 (0.2095) acc 93.7500 (94.6875) lr 1.0000e-05 eta 0:20:36
epoch [22/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.1520 (0.2114) acc 93.7500 (94.5924) lr 1.0000e-05 eta 0:20:34
epoch [22/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0034 (0.2056) acc 100.0000 (94.6615) lr 1.0000e-05 eta 0:20:32
epoch [22/50] batch [125/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1171 (0.2039) acc 93.7500 (94.6750) lr 1.0000e-05 eta 0:20:30
epoch [22/50] batch [130/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.2152 (0.2022) acc 93.7500 (94.6635) lr 1.0000e-05 eta 0:20:28
epoch [22/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0299 (0.1993) acc 96.8750 (94.6991) lr 1.0000e-05 eta 0:20:26
epoch [22/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.3849 (0.2016) acc 96.8750 (94.6875) lr 1.0000e-05 eta 0:20:24
epoch [22/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.3838 (0.2064) acc 96.8750 (94.6552) lr 1.0000e-05 eta 0:20:22
epoch [22/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0087 (0.2068) acc 100.0000 (94.6458) lr 1.0000e-05 eta 0:20:20
epoch [22/50] batch [155/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0660 (0.2067) acc 96.8750 (94.6573) lr 1.0000e-05 eta 0:20:19
epoch [22/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0110 (0.2065) acc 100.0000 (94.6680) lr 1.0000e-05 eta 0:20:17
epoch [22/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0084 (0.2050) acc 100.0000 (94.6591) lr 1.0000e-05 eta 0:20:15
epoch [22/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0491 (0.2034) acc 96.8750 (94.6875) lr 1.0000e-05 eta 0:20:14
epoch [22/50] batch [175/180] time 0.238 (0.240) data 0.000 (0.003) loss 0.2217 (0.2044) acc 87.5000 (94.6429) lr 1.0000e-05 eta 0:20:12
Adjusting learning rate of group 0 to 1.9048e-03.
epoch [22/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.3251 (0.2065) acc 90.6250 (94.5486) lr 1.9048e-03 eta 0:20:10
在 *val* 集上测试
=> result
* total: 824
* correct: 769
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 89.5%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 4	acc: 66.7%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 6	acc: 100.0%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 4	acc: 66.7%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 6	acc: 85.7%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 2	acc: 66.7%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 7	acc: 63.6%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 6	acc: 85.7%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 1	acc: 33.3%
* class: 73 (pyramid)	total: 6	correct: 6	acc: 100.0%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 4	acc: 66.7%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 4	acc: 66.7%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.6%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [23/50] batch [5/180] time 0.237 (0.344) data 0.000 (0.107) loss 0.0617 (0.0875) acc 96.8750 (97.5000) lr 1.9048e-03 eta 0:28:53
epoch [23/50] batch [10/180] time 0.238 (0.291) data 0.000 (0.053) loss 0.2101 (0.1934) acc 96.8750 (96.2500) lr 1.9048e-03 eta 0:24:22
epoch [23/50] batch [15/180] time 0.237 (0.273) data 0.000 (0.036) loss 0.0339 (0.1737) acc 100.0000 (96.0417) lr 1.9048e-03 eta 0:22:51
epoch [23/50] batch [20/180] time 0.237 (0.264) data 0.000 (0.027) loss 0.0062 (0.2028) acc 100.0000 (95.7812) lr 1.9048e-03 eta 0:22:05
epoch [23/50] batch [25/180] time 0.237 (0.259) data 0.000 (0.021) loss 0.0780 (0.2114) acc 96.8750 (95.6250) lr 1.9048e-03 eta 0:21:37
epoch [23/50] batch [30/180] time 0.237 (0.255) data 0.000 (0.018) loss 0.3286 (0.1924) acc 90.6250 (95.8333) lr 1.9048e-03 eta 0:21:18
epoch [23/50] batch [35/180] time 0.238 (0.253) data 0.000 (0.015) loss 0.4626 (0.1979) acc 93.7500 (96.0714) lr 1.9048e-03 eta 0:21:04
epoch [23/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.013) loss 0.1152 (0.2049) acc 96.8750 (96.0156) lr 1.9048e-03 eta 0:20:54
epoch [23/50] batch [45/180] time 0.238 (0.249) data 0.000 (0.012) loss 0.2974 (0.1942) acc 93.7500 (96.0417) lr 1.9048e-03 eta 0:20:45
epoch [23/50] batch [50/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.1455 (0.1934) acc 93.7500 (95.8750) lr 1.9048e-03 eta 0:20:38
epoch [23/50] batch [55/180] time 0.238 (0.247) data 0.000 (0.010) loss 0.1033 (0.1922) acc 96.8750 (95.9659) lr 1.9048e-03 eta 0:20:32
epoch [23/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2552 (0.1875) acc 87.5000 (95.8333) lr 1.9048e-03 eta 0:20:27
epoch [23/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0066 (0.1961) acc 100.0000 (95.6731) lr 1.9048e-03 eta 0:20:22
epoch [23/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1136 (0.1895) acc 96.8750 (95.7589) lr 1.9048e-03 eta 0:20:18
epoch [23/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.3842 (0.1924) acc 90.6250 (95.6667) lr 1.9048e-03 eta 0:20:14
epoch [23/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.5233 (0.1998) acc 93.7500 (95.5469) lr 1.9048e-03 eta 0:20:11
epoch [23/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.0544 (0.1991) acc 96.8750 (95.5882) lr 1.9048e-03 eta 0:20:08
epoch [23/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0597 (0.1951) acc 96.8750 (95.5903) lr 1.9048e-03 eta 0:20:05
epoch [23/50] batch [95/180] time 0.238 (0.243) data 0.001 (0.006) loss 0.0125 (0.1984) acc 100.0000 (95.4605) lr 1.9048e-03 eta 0:20:02
epoch [23/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0632 (0.1938) acc 96.8750 (95.5312) lr 1.9048e-03 eta 0:19:59
epoch [23/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0148 (0.1927) acc 100.0000 (95.5060) lr 1.9048e-03 eta 0:19:57
epoch [23/50] batch [110/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1181 (0.1980) acc 93.7500 (95.4830) lr 1.9048e-03 eta 0:19:54
epoch [23/50] batch [115/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.1261 (0.1962) acc 96.8750 (95.5435) lr 1.9048e-03 eta 0:19:52
epoch [23/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2447 (0.1963) acc 93.7500 (95.5208) lr 1.9048e-03 eta 0:19:50
epoch [23/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0943 (0.1946) acc 93.7500 (95.5000) lr 1.9048e-03 eta 0:19:48
epoch [23/50] batch [130/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0032 (0.1938) acc 100.0000 (95.4808) lr 1.9048e-03 eta 0:19:46
epoch [23/50] batch [135/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0235 (0.1962) acc 100.0000 (95.4861) lr 1.9048e-03 eta 0:19:44
epoch [23/50] batch [140/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1906 (0.1933) acc 93.7500 (95.4911) lr 1.9048e-03 eta 0:19:42
epoch [23/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1046 (0.1917) acc 93.7500 (95.4310) lr 1.9048e-03 eta 0:19:40
epoch [23/50] batch [150/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0064 (0.1945) acc 100.0000 (95.3750) lr 1.9048e-03 eta 0:19:38
epoch [23/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0272 (0.1930) acc 100.0000 (95.4435) lr 1.9048e-03 eta 0:19:36
epoch [23/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.2363 (0.1918) acc 93.7500 (95.4102) lr 1.9048e-03 eta 0:19:35
epoch [23/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.6929 (0.2007) acc 90.6250 (95.3030) lr 1.9048e-03 eta 0:19:33
epoch [23/50] batch [170/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0609 (0.2037) acc 96.8750 (95.2206) lr 1.9048e-03 eta 0:19:31
epoch [23/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.5077 (0.2038) acc 96.8750 (95.2857) lr 1.9048e-03 eta 0:19:30
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [23/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1426 (0.2038) acc 96.8750 (95.3125) lr 1.8763e-03 eta 0:19:28
在 *val* 集上测试
=> result
* total: 824
* correct: 765
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 88.9%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 5	acc: 71.4%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 10	acc: 90.9%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 1	acc: 16.7%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.3%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [24/50] batch [5/180] time 0.238 (0.351) data 0.000 (0.113) loss 0.0525 (0.1463) acc 96.8750 (93.7500) lr 1.8763e-03 eta 0:28:26
epoch [24/50] batch [10/180] time 0.237 (0.294) data 0.000 (0.057) loss 0.1125 (0.1004) acc 93.7500 (95.3125) lr 1.8763e-03 eta 0:23:47
epoch [24/50] batch [15/180] time 0.237 (0.275) data 0.000 (0.038) loss 0.1875 (0.1023) acc 96.8750 (96.0417) lr 1.8763e-03 eta 0:22:14
epoch [24/50] batch [20/180] time 0.237 (0.266) data 0.000 (0.028) loss 0.7884 (0.1373) acc 96.8750 (96.0938) lr 1.8763e-03 eta 0:21:27
epoch [24/50] batch [25/180] time 0.238 (0.260) data 0.000 (0.023) loss 0.0247 (0.1595) acc 100.0000 (95.7500) lr 1.8763e-03 eta 0:20:58
epoch [24/50] batch [30/180] time 0.238 (0.257) data 0.000 (0.019) loss 0.2998 (0.1581) acc 93.7500 (95.6250) lr 1.8763e-03 eta 0:20:39
epoch [24/50] batch [35/180] time 0.237 (0.254) data 0.000 (0.016) loss 0.2177 (0.1815) acc 90.6250 (95.1786) lr 1.8763e-03 eta 0:20:24
epoch [24/50] batch [40/180] time 0.237 (0.252) data 0.000 (0.014) loss 0.8469 (0.1987) acc 87.5000 (95.0000) lr 1.8763e-03 eta 0:20:13
epoch [24/50] batch [45/180] time 0.237 (0.250) data 0.000 (0.013) loss 0.0653 (0.1956) acc 96.8750 (95.0694) lr 1.8763e-03 eta 0:20:04
epoch [24/50] batch [50/180] time 0.238 (0.249) data 0.000 (0.011) loss 0.0128 (0.2018) acc 100.0000 (95.0625) lr 1.8763e-03 eta 0:19:57
epoch [24/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.010) loss 0.0596 (0.2018) acc 96.8750 (95.1136) lr 1.8763e-03 eta 0:19:50
epoch [24/50] batch [60/180] time 0.238 (0.247) data 0.000 (0.010) loss 0.0667 (0.2059) acc 96.8750 (95.2083) lr 1.8763e-03 eta 0:19:45
epoch [24/50] batch [65/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.1422 (0.2048) acc 90.6250 (95.2404) lr 1.8763e-03 eta 0:19:40
epoch [24/50] batch [70/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0710 (0.2074) acc 96.8750 (95.1786) lr 1.8763e-03 eta 0:19:36
epoch [24/50] batch [75/180] time 0.238 (0.245) data 0.000 (0.008) loss 0.0216 (0.1997) acc 100.0000 (95.2500) lr 1.8763e-03 eta 0:19:32
epoch [24/50] batch [80/180] time 0.238 (0.245) data 0.000 (0.007) loss 0.6793 (0.2163) acc 90.6250 (94.9609) lr 1.8763e-03 eta 0:19:29
epoch [24/50] batch [85/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.0784 (0.2120) acc 93.7500 (95.0368) lr 1.8763e-03 eta 0:19:26
epoch [24/50] batch [90/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.5119 (0.2087) acc 96.8750 (95.2083) lr 1.8763e-03 eta 0:19:23
epoch [24/50] batch [95/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.1052 (0.2041) acc 96.8750 (95.2632) lr 1.8763e-03 eta 0:19:20
epoch [24/50] batch [100/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.1755 (0.1985) acc 90.6250 (95.3438) lr 1.8763e-03 eta 0:19:17
epoch [24/50] batch [105/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0157 (0.1912) acc 100.0000 (95.5060) lr 1.8763e-03 eta 0:19:15
epoch [24/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0713 (0.1875) acc 96.8750 (95.5114) lr 1.8763e-03 eta 0:19:12
epoch [24/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1627 (0.1859) acc 96.8750 (95.5163) lr 1.8763e-03 eta 0:19:10
epoch [24/50] batch [120/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0285 (0.1851) acc 100.0000 (95.5469) lr 1.8763e-03 eta 0:19:08
epoch [24/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.0461 (0.1885) acc 96.8750 (95.5250) lr 1.8763e-03 eta 0:19:06
epoch [24/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.0564 (0.1906) acc 96.8750 (95.5048) lr 1.8763e-03 eta 0:19:04
epoch [24/50] batch [135/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.1950 (0.1897) acc 90.6250 (95.4630) lr 1.8763e-03 eta 0:19:02
epoch [24/50] batch [140/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0586 (0.1909) acc 96.8750 (95.4688) lr 1.8763e-03 eta 0:19:00
epoch [24/50] batch [145/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.1758 (0.1908) acc 93.7500 (95.3448) lr 1.8763e-03 eta 0:18:58
epoch [24/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.6896 (0.1927) acc 87.5000 (95.3125) lr 1.8763e-03 eta 0:18:56
epoch [24/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0640 (0.1926) acc 96.8750 (95.3226) lr 1.8763e-03 eta 0:18:54
epoch [24/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1747 (0.1939) acc 90.6250 (95.2344) lr 1.8763e-03 eta 0:18:53
epoch [24/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.4660 (0.1955) acc 96.8750 (95.2652) lr 1.8763e-03 eta 0:18:51
epoch [24/50] batch [170/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0104 (0.1942) acc 100.0000 (95.3125) lr 1.8763e-03 eta 0:18:49
epoch [24/50] batch [175/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.1923 (0.1933) acc 96.8750 (95.3393) lr 1.8763e-03 eta 0:18:47
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [24/50] batch [180/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.2042 (0.1953) acc 87.5000 (95.2431) lr 1.0000e-05 eta 0:18:46
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.2%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 4	acc: 100.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 10	acc: 90.9%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 0	acc: 0.0%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.6%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [25/50] batch [5/180] time 0.238 (0.356) data 0.000 (0.116) loss 0.0603 (0.2441) acc 96.8750 (95.6250) lr 1.0000e-05 eta 0:27:45
epoch [25/50] batch [10/180] time 0.238 (0.297) data 0.000 (0.058) loss 0.0147 (0.1712) acc 100.0000 (95.3125) lr 1.0000e-05 eta 0:23:07
epoch [25/50] batch [15/180] time 0.238 (0.277) data 0.000 (0.039) loss 0.0169 (0.1456) acc 100.0000 (95.6250) lr 1.0000e-05 eta 0:21:33
epoch [25/50] batch [20/180] time 0.238 (0.267) data 0.000 (0.029) loss 0.0182 (0.1635) acc 100.0000 (95.9375) lr 1.0000e-05 eta 0:20:46
epoch [25/50] batch [25/180] time 0.237 (0.262) data 0.000 (0.023) loss 0.0579 (0.1823) acc 96.8750 (95.7500) lr 1.0000e-05 eta 0:20:17
epoch [25/50] batch [30/180] time 0.237 (0.258) data 0.000 (0.019) loss 0.0119 (0.1700) acc 100.0000 (95.9375) lr 1.0000e-05 eta 0:19:57
epoch [25/50] batch [35/180] time 0.238 (0.255) data 0.000 (0.017) loss 0.0067 (0.1571) acc 100.0000 (96.2500) lr 1.0000e-05 eta 0:19:43
epoch [25/50] batch [40/180] time 0.237 (0.253) data 0.000 (0.015) loss 0.1547 (0.1588) acc 93.7500 (96.0156) lr 1.0000e-05 eta 0:19:31
epoch [25/50] batch [45/180] time 0.238 (0.251) data 0.000 (0.013) loss 0.2353 (0.1708) acc 93.7500 (95.8333) lr 1.0000e-05 eta 0:19:22
epoch [25/50] batch [50/180] time 0.237 (0.250) data 0.000 (0.012) loss 0.3805 (0.1783) acc 90.6250 (95.7500) lr 1.0000e-05 eta 0:19:15
epoch [25/50] batch [55/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.2227 (0.1794) acc 90.6250 (95.6250) lr 1.0000e-05 eta 0:19:08
epoch [25/50] batch [60/180] time 0.237 (0.248) data 0.000 (0.010) loss 0.1130 (0.1750) acc 93.7500 (95.5729) lr 1.0000e-05 eta 0:19:03
epoch [25/50] batch [65/180] time 0.238 (0.247) data 0.000 (0.009) loss 0.3293 (0.1837) acc 90.6250 (95.3846) lr 1.0000e-05 eta 0:18:58
epoch [25/50] batch [70/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0066 (0.1800) acc 100.0000 (95.4464) lr 1.0000e-05 eta 0:18:54
epoch [25/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.1372 (0.1756) acc 96.8750 (95.4167) lr 1.0000e-05 eta 0:18:50
epoch [25/50] batch [80/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.7125 (0.1773) acc 84.3750 (95.3906) lr 1.0000e-05 eta 0:18:46
epoch [25/50] batch [85/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.1906 (0.1743) acc 90.6250 (95.4412) lr 1.0000e-05 eta 0:18:43
epoch [25/50] batch [90/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.1396 (0.1758) acc 90.6250 (95.5208) lr 1.0000e-05 eta 0:18:40
epoch [25/50] batch [95/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.1163 (0.1709) acc 96.8750 (95.5921) lr 1.0000e-05 eta 0:18:37
epoch [25/50] batch [100/180] time 0.238 (0.244) data 0.000 (0.006) loss 0.0616 (0.1703) acc 96.8750 (95.6250) lr 1.0000e-05 eta 0:18:35
epoch [25/50] batch [105/180] time 0.238 (0.243) data 0.000 (0.006) loss 0.0126 (0.1771) acc 100.0000 (95.5357) lr 1.0000e-05 eta 0:18:32
epoch [25/50] batch [110/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.1115 (0.1720) acc 90.6250 (95.5398) lr 1.0000e-05 eta 0:18:30
epoch [25/50] batch [115/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.4952 (0.1769) acc 93.7500 (95.4620) lr 1.0000e-05 eta 0:18:28
epoch [25/50] batch [120/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.2289 (0.1727) acc 93.7500 (95.5469) lr 1.0000e-05 eta 0:18:25
epoch [25/50] batch [125/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.1714 (0.1735) acc 96.8750 (95.6000) lr 1.0000e-05 eta 0:18:23
epoch [25/50] batch [130/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.4613 (0.1786) acc 93.7500 (95.6010) lr 1.0000e-05 eta 0:18:21
epoch [25/50] batch [135/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.1928 (0.1755) acc 93.7500 (95.6250) lr 1.0000e-05 eta 0:18:19
epoch [25/50] batch [140/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.6022 (0.1814) acc 90.6250 (95.4688) lr 1.0000e-05 eta 0:18:17
epoch [25/50] batch [145/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.1344 (0.1782) acc 96.8750 (95.4957) lr 1.0000e-05 eta 0:18:15
epoch [25/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0463 (0.1812) acc 96.8750 (95.4583) lr 1.0000e-05 eta 0:18:13
epoch [25/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0489 (0.1834) acc 96.8750 (95.4435) lr 1.0000e-05 eta 0:18:12
epoch [25/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0219 (0.1847) acc 100.0000 (95.4883) lr 1.0000e-05 eta 0:18:10
epoch [25/50] batch [165/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0552 (0.1849) acc 100.0000 (95.4924) lr 1.0000e-05 eta 0:18:08
epoch [25/50] batch [170/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0295 (0.1873) acc 100.0000 (95.4412) lr 1.0000e-05 eta 0:18:06
epoch [25/50] batch [175/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.2472 (0.1883) acc 96.8750 (95.4464) lr 1.0000e-05 eta 0:18:05
Adjusting learning rate of group 0 to 1.8763e-03.
epoch [25/50] batch [180/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0782 (0.1859) acc 93.7500 (95.4861) lr 1.8763e-03 eta 0:18:03
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.3%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 10	acc: 90.9%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 10	acc: 90.9%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 8	acc: 100.0%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 0	acc: 0.0%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.6%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
检查点已保存到 ./output/25-03-31-00-24-00/CLIP_promptLearner/model.pth.tar-25
epoch [26/50] batch [5/180] time 0.237 (0.343) data 0.000 (0.106) loss 0.0133 (0.2437) acc 100.0000 (95.0000) lr 1.8763e-03 eta 0:25:42
epoch [26/50] batch [10/180] time 0.237 (0.290) data 0.000 (0.053) loss 0.2697 (0.2772) acc 93.7500 (94.6875) lr 1.8763e-03 eta 0:21:43
epoch [26/50] batch [15/180] time 0.238 (0.273) data 0.000 (0.035) loss 0.0764 (0.2297) acc 96.8750 (95.0000) lr 1.8763e-03 eta 0:20:22
epoch [26/50] batch [20/180] time 0.237 (0.264) data 0.000 (0.027) loss 0.1412 (0.2126) acc 96.8750 (95.4688) lr 1.8763e-03 eta 0:19:42
epoch [26/50] batch [25/180] time 0.237 (0.259) data 0.000 (0.021) loss 0.1879 (0.2029) acc 90.6250 (95.2500) lr 1.8763e-03 eta 0:19:17
epoch [26/50] batch [30/180] time 0.237 (0.255) data 0.000 (0.018) loss 0.3780 (0.2297) acc 87.5000 (94.4792) lr 1.8763e-03 eta 0:19:00
epoch [26/50] batch [35/180] time 0.237 (0.252) data 0.000 (0.015) loss 0.2405 (0.2504) acc 93.7500 (93.8393) lr 1.8763e-03 eta 0:18:47
epoch [26/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.013) loss 0.4571 (0.2395) acc 90.6250 (94.0625) lr 1.8763e-03 eta 0:18:37
epoch [26/50] batch [45/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.4411 (0.2332) acc 90.6250 (94.2361) lr 1.8763e-03 eta 0:18:29
epoch [26/50] batch [50/180] time 0.237 (0.248) data 0.000 (0.011) loss 0.0027 (0.2219) acc 100.0000 (94.4375) lr 1.8763e-03 eta 0:18:23
epoch [26/50] batch [55/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.3701 (0.2340) acc 96.8750 (94.6023) lr 1.8763e-03 eta 0:18:17
epoch [26/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2213 (0.2313) acc 90.6250 (94.3750) lr 1.8763e-03 eta 0:18:13
epoch [26/50] batch [65/180] time 0.238 (0.246) data 0.000 (0.008) loss 0.0309 (0.2213) acc 96.8750 (94.4231) lr 1.8763e-03 eta 0:18:08
epoch [26/50] batch [70/180] time 0.238 (0.245) data 0.000 (0.008) loss 0.2863 (0.2218) acc 96.8750 (94.5982) lr 1.8763e-03 eta 0:18:05
epoch [26/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.1076 (0.2293) acc 93.7500 (94.5000) lr 1.8763e-03 eta 0:18:01
epoch [26/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.0887 (0.2198) acc 93.7500 (94.6484) lr 1.8763e-03 eta 0:17:58
epoch [26/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.1418 (0.2169) acc 96.8750 (94.5956) lr 1.8763e-03 eta 0:17:55
epoch [26/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0593 (0.2165) acc 96.8750 (94.6528) lr 1.8763e-03 eta 0:17:52
epoch [26/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.1929 (0.2117) acc 90.6250 (94.6711) lr 1.8763e-03 eta 0:17:50
epoch [26/50] batch [100/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.2492 (0.2139) acc 90.6250 (94.6875) lr 1.8763e-03 eta 0:17:47
epoch [26/50] batch [105/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.3374 (0.2139) acc 93.7500 (94.6429) lr 1.8763e-03 eta 0:17:45
epoch [26/50] batch [110/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0970 (0.2072) acc 93.7500 (94.7443) lr 1.8763e-03 eta 0:17:43
epoch [26/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.4592 (0.2075) acc 90.6250 (94.7826) lr 1.8763e-03 eta 0:17:40
epoch [26/50] batch [120/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.2395 (0.2024) acc 93.7500 (94.8958) lr 1.8763e-03 eta 0:17:38
epoch [26/50] batch [125/180] time 0.238 (0.242) data 0.000 (0.004) loss 0.0996 (0.2011) acc 96.8750 (94.8750) lr 1.8763e-03 eta 0:17:36
epoch [26/50] batch [130/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.0855 (0.1960) acc 96.8750 (94.9760) lr 1.8763e-03 eta 0:17:35
epoch [26/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1148 (0.1941) acc 93.7500 (94.9537) lr 1.8763e-03 eta 0:17:33
epoch [26/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0584 (0.1956) acc 96.8750 (94.9777) lr 1.8763e-03 eta 0:17:31
epoch [26/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0080 (0.1941) acc 100.0000 (95.0647) lr 1.8763e-03 eta 0:17:29
epoch [26/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.004) loss 0.3297 (0.1942) acc 93.7500 (95.0417) lr 1.8763e-03 eta 0:17:27
epoch [26/50] batch [155/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0352 (0.1962) acc 96.8750 (94.9798) lr 1.8763e-03 eta 0:17:26
epoch [26/50] batch [160/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.0566 (0.1916) acc 96.8750 (95.0586) lr 1.8763e-03 eta 0:17:24
epoch [26/50] batch [165/180] time 0.237 (0.241) data 0.000 (0.003) loss 0.5010 (0.1939) acc 96.8750 (95.0758) lr 1.8763e-03 eta 0:17:22
epoch [26/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0116 (0.1895) acc 100.0000 (95.1654) lr 1.8763e-03 eta 0:17:21
epoch [26/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0205 (0.1885) acc 100.0000 (95.1786) lr 1.8763e-03 eta 0:17:19
由于设置了 warmup_recount，且现在预热结束，因此重置 epoch 为 -1
epoch [26/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0216 (0.1898) acc 100.0000 (95.1736) lr 1.8443e-03 eta 0:17:18
在 *val* 集上测试
=> result
* total: 824
* correct: 767
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 89.3%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 3	acc: 50.0%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 3	acc: 60.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 7	acc: 87.5%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 5	acc: 83.3%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 3	acc: 75.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 7	acc: 63.6%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 89.7%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [27/50] batch [5/180] time 0.237 (0.336) data 0.000 (0.098) loss 0.0086 (0.2014) acc 100.0000 (96.2500) lr 1.8443e-03 eta 0:24:11
epoch [27/50] batch [10/180] time 0.237 (0.287) data 0.000 (0.049) loss 0.0027 (0.1478) acc 100.0000 (95.6250) lr 1.8443e-03 eta 0:20:36
epoch [27/50] batch [15/180] time 0.237 (0.270) data 0.000 (0.033) loss 0.2184 (0.1526) acc 93.7500 (95.6250) lr 1.8443e-03 eta 0:19:23
epoch [27/50] batch [20/180] time 0.237 (0.262) data 0.000 (0.025) loss 0.2893 (0.1671) acc 93.7500 (95.7812) lr 1.8443e-03 eta 0:18:46
epoch [27/50] batch [25/180] time 0.237 (0.257) data 0.000 (0.020) loss 0.0715 (0.1632) acc 96.8750 (95.3750) lr 1.8443e-03 eta 0:18:23
epoch [27/50] batch [30/180] time 0.238 (0.254) data 0.000 (0.017) loss 0.0835 (0.1632) acc 93.7500 (95.4167) lr 1.8443e-03 eta 0:18:08
epoch [27/50] batch [35/180] time 0.237 (0.251) data 0.000 (0.014) loss 0.1752 (0.1526) acc 96.8750 (95.6250) lr 1.8443e-03 eta 0:17:57
epoch [27/50] batch [40/180] time 0.237 (0.250) data 0.000 (0.012) loss 0.0843 (0.1468) acc 93.7500 (95.5469) lr 1.8443e-03 eta 0:17:48
epoch [27/50] batch [45/180] time 0.238 (0.248) data 0.000 (0.011) loss 0.2244 (0.1537) acc 93.7500 (95.5556) lr 1.8443e-03 eta 0:17:41
epoch [27/50] batch [50/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.1209 (0.1509) acc 96.8750 (95.4375) lr 1.8443e-03 eta 0:17:35
epoch [27/50] batch [55/180] time 0.237 (0.246) data 0.000 (0.009) loss 0.2170 (0.1640) acc 93.7500 (95.3409) lr 1.8443e-03 eta 0:17:30
epoch [27/50] batch [60/180] time 0.237 (0.246) data 0.000 (0.008) loss 0.0101 (0.1562) acc 100.0000 (95.4688) lr 1.8443e-03 eta 0:17:26
epoch [27/50] batch [65/180] time 0.238 (0.245) data 0.000 (0.008) loss 0.1648 (0.1555) acc 96.8750 (95.5769) lr 1.8443e-03 eta 0:17:22
epoch [27/50] batch [70/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.4989 (0.1586) acc 90.6250 (95.6250) lr 1.8443e-03 eta 0:17:19
epoch [27/50] batch [75/180] time 0.237 (0.244) data 0.000 (0.007) loss 0.3241 (0.1722) acc 90.6250 (95.4583) lr 1.8443e-03 eta 0:17:15
epoch [27/50] batch [80/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.0046 (0.1706) acc 100.0000 (95.4688) lr 1.8443e-03 eta 0:17:12
epoch [27/50] batch [85/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.0119 (0.1710) acc 100.0000 (95.4779) lr 1.8443e-03 eta 0:17:09
epoch [27/50] batch [90/180] time 0.237 (0.243) data 0.000 (0.006) loss 0.2848 (0.1833) acc 87.5000 (95.2431) lr 1.8443e-03 eta 0:17:07
epoch [27/50] batch [95/180] time 0.237 (0.243) data 0.000 (0.005) loss 0.0034 (0.1799) acc 100.0000 (95.3289) lr 1.8443e-03 eta 0:17:04
epoch [27/50] batch [100/180] time 0.237 (0.242) data 0.000 (0.005) loss 0.5867 (0.1820) acc 87.5000 (95.1875) lr 1.8443e-03 eta 0:17:02
epoch [27/50] batch [105/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0025 (0.1810) acc 100.0000 (95.2976) lr 1.8443e-03 eta 0:17:00
epoch [27/50] batch [110/180] time 0.238 (0.242) data 0.000 (0.005) loss 0.0224 (0.1784) acc 100.0000 (95.3693) lr 1.8443e-03 eta 0:16:58
epoch [27/50] batch [115/180] time 0.237 (0.242) data 0.000 (0.004) loss 0.1317 (0.1791) acc 93.7500 (95.3804) lr 1.8443e-03 eta 0:16:56
epoch [27/50] batch [120/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4646 (0.1793) acc 96.8750 (95.3906) lr 1.8443e-03 eta 0:16:54
epoch [27/50] batch [125/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.1148 (0.1776) acc 93.7500 (95.3500) lr 1.8443e-03 eta 0:16:52
epoch [27/50] batch [130/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.4135 (0.1803) acc 93.7500 (95.3846) lr 1.8443e-03 eta 0:16:50
epoch [27/50] batch [135/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.7173 (0.1847) acc 93.7500 (95.3241) lr 1.8443e-03 eta 0:16:48
epoch [27/50] batch [140/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0303 (0.1822) acc 96.8750 (95.2679) lr 1.8443e-03 eta 0:16:46
epoch [27/50] batch [145/180] time 0.237 (0.241) data 0.000 (0.004) loss 0.0449 (0.1819) acc 96.8750 (95.2155) lr 1.8443e-03 eta 0:16:45
epoch [27/50] batch [150/180] time 0.238 (0.241) data 0.000 (0.003) loss 0.0066 (0.1856) acc 100.0000 (95.1875) lr 1.8443e-03 eta 0:16:43
epoch [27/50] batch [155/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1572 (0.1875) acc 93.7500 (95.0806) lr 1.8443e-03 eta 0:16:41
epoch [27/50] batch [160/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0381 (0.1864) acc 96.8750 (95.0977) lr 1.8443e-03 eta 0:16:40
epoch [27/50] batch [165/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.2707 (0.1845) acc 93.7500 (95.1136) lr 1.8443e-03 eta 0:16:38
epoch [27/50] batch [170/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.1765 (0.1860) acc 93.7500 (95.1103) lr 1.8443e-03 eta 0:16:36
epoch [27/50] batch [175/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.0679 (0.1830) acc 96.8750 (95.1607) lr 1.8443e-03 eta 0:16:35
Adjusting learning rate of group 0 to 1.0000e-05.
epoch [27/50] batch [180/180] time 0.237 (0.240) data 0.000 (0.003) loss 0.4848 (0.1843) acc 93.7500 (95.1910) lr 1.0000e-05 eta 0:16:33
在 *val* 集上测试
=> result
* total: 824
* correct: 769
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 89.9%
=> per-class result
* class: 0 (face)	total: 44	correct: 44	acc: 100.0%
* class: 1 (leopard)	total: 20	correct: 19	acc: 95.0%
* class: 2 (motorbike)	total: 80	correct: 80	acc: 100.0%
* class: 3 (accordion)	total: 6	correct: 4	acc: 66.7%
* class: 4 (airplane)	total: 80	correct: 80	acc: 100.0%
* class: 5 (anchor)	total: 4	correct: 3	acc: 75.0%
* class: 6 (ant)	total: 4	correct: 3	acc: 75.0%
* class: 7 (barrel)	total: 5	correct: 5	acc: 100.0%
* class: 8 (bass)	total: 5	correct: 5	acc: 100.0%
* class: 9 (beaver)	total: 5	correct: 5	acc: 100.0%
* class: 10 (binocular)	total: 3	correct: 2	acc: 66.7%
* class: 11 (bonsai)	total: 13	correct: 13	acc: 100.0%
* class: 12 (brain)	total: 10	correct: 10	acc: 100.0%
* class: 13 (brontosaurus)	total: 4	correct: 4	acc: 100.0%
* class: 14 (buddha)	total: 8	correct: 8	acc: 100.0%
* class: 15 (butterfly)	total: 9	correct: 8	acc: 88.9%
* class: 16 (camera)	total: 5	correct: 4	acc: 80.0%
* class: 17 (cannon)	total: 4	correct: 4	acc: 100.0%
* class: 18 (car_side)	total: 12	correct: 12	acc: 100.0%
* class: 19 (ceiling_fan)	total: 5	correct: 4	acc: 80.0%
* class: 20 (cellphone)	total: 6	correct: 6	acc: 100.0%
* class: 21 (chair)	total: 6	correct: 2	acc: 33.3%
* class: 22 (chandelier)	total: 11	correct: 11	acc: 100.0%
* class: 23 (cougar_body)	total: 5	correct: 5	acc: 100.0%
* class: 24 (cougar_face)	total: 7	correct: 6	acc: 85.7%
* class: 25 (crab)	total: 7	correct: 7	acc: 100.0%
* class: 26 (crayfish)	total: 7	correct: 7	acc: 100.0%
* class: 27 (crocodile)	total: 5	correct: 5	acc: 100.0%
* class: 28 (crocodile_head)	total: 5	correct: 4	acc: 80.0%
* class: 29 (cup)	total: 6	correct: 5	acc: 83.3%
* class: 30 (dalmatian)	total: 7	correct: 7	acc: 100.0%
* class: 31 (dollar_bill)	total: 5	correct: 5	acc: 100.0%
* class: 32 (dolphin)	total: 6	correct: 5	acc: 83.3%
* class: 33 (dragonfly)	total: 7	correct: 6	acc: 85.7%
* class: 34 (electric_guitar)	total: 8	correct: 6	acc: 75.0%
* class: 35 (elephant)	total: 6	correct: 5	acc: 83.3%
* class: 36 (emu)	total: 5	correct: 5	acc: 100.0%
* class: 37 (euphonium)	total: 6	correct: 6	acc: 100.0%
* class: 38 (ewer)	total: 8	correct: 6	acc: 75.0%
* class: 39 (ferry)	total: 7	correct: 7	acc: 100.0%
* class: 40 (flamingo)	total: 7	correct: 5	acc: 71.4%
* class: 41 (flamingo_head)	total: 4	correct: 4	acc: 100.0%
* class: 42 (garfield)	total: 3	correct: 2	acc: 66.7%
* class: 43 (gerenuk)	total: 3	correct: 3	acc: 100.0%
* class: 44 (gramophone)	total: 5	correct: 4	acc: 80.0%
* class: 45 (grand_piano)	total: 10	correct: 10	acc: 100.0%
* class: 46 (hawksbill)	total: 10	correct: 10	acc: 100.0%
* class: 47 (headphone)	total: 4	correct: 4	acc: 100.0%
* class: 48 (hedgehog)	total: 5	correct: 5	acc: 100.0%
* class: 49 (helicopter)	total: 9	correct: 8	acc: 88.9%
* class: 50 (ibis)	total: 8	correct: 8	acc: 100.0%
* class: 51 (inline_skate)	total: 3	correct: 3	acc: 100.0%
* class: 52 (joshua_tree)	total: 6	correct: 6	acc: 100.0%
* class: 53 (kangaroo)	total: 9	correct: 9	acc: 100.0%
* class: 54 (ketch)	total: 11	correct: 8	acc: 72.7%
* class: 55 (lamp)	total: 6	correct: 6	acc: 100.0%
* class: 56 (laptop)	total: 8	correct: 8	acc: 100.0%
* class: 57 (llama)	total: 8	correct: 7	acc: 87.5%
* class: 58 (lobster)	total: 4	correct: 1	acc: 25.0%
* class: 59 (lotus)	total: 7	correct: 5	acc: 71.4%
* class: 60 (mandolin)	total: 4	correct: 4	acc: 100.0%
* class: 61 (mayfly)	total: 4	correct: 4	acc: 100.0%
* class: 62 (menorah)	total: 9	correct: 9	acc: 100.0%
* class: 63 (metronome)	total: 3	correct: 3	acc: 100.0%
* class: 64 (minaret)	total: 8	correct: 6	acc: 75.0%
* class: 65 (nautilus)	total: 6	correct: 6	acc: 100.0%
* class: 66 (octopus)	total: 4	correct: 3	acc: 75.0%
* class: 67 (okapi)	total: 4	correct: 4	acc: 100.0%
* class: 68 (pagoda)	total: 5	correct: 5	acc: 100.0%
* class: 69 (panda)	total: 4	correct: 4	acc: 100.0%
* class: 70 (pigeon)	total: 4	correct: 4	acc: 100.0%
* class: 71 (pizza)	total: 5	correct: 5	acc: 100.0%
* class: 72 (platypus)	total: 3	correct: 2	acc: 66.7%
* class: 73 (pyramid)	total: 6	correct: 5	acc: 83.3%
* class: 74 (revolver)	total: 8	correct: 8	acc: 100.0%
* class: 75 (rhino)	total: 6	correct: 6	acc: 100.0%
* class: 76 (rooster)	total: 5	correct: 5	acc: 100.0%
* class: 77 (saxophone)	total: 4	correct: 4	acc: 100.0%
* class: 78 (schooner)	total: 6	correct: 3	acc: 50.0%
* class: 79 (scissors)	total: 4	correct: 2	acc: 50.0%
* class: 80 (scorpion)	total: 8	correct: 6	acc: 75.0%
* class: 81 (sea_horse)	total: 6	correct: 6	acc: 100.0%
* class: 82 (snoopy)	total: 4	correct: 4	acc: 100.0%
* class: 83 (soccer_ball)	total: 6	correct: 6	acc: 100.0%
* class: 84 (stapler)	total: 4	correct: 3	acc: 75.0%
* class: 85 (starfish)	total: 9	correct: 9	acc: 100.0%
* class: 86 (stegosaurus)	total: 6	correct: 6	acc: 100.0%
* class: 87 (stop_sign)	total: 6	correct: 6	acc: 100.0%
* class: 88 (strawberry)	total: 4	correct: 4	acc: 100.0%
* class: 89 (sunflower)	total: 8	correct: 8	acc: 100.0%
* class: 90 (tick)	total: 5	correct: 5	acc: 100.0%
* class: 91 (trilobite)	total: 9	correct: 9	acc: 100.0%
* class: 92 (umbrella)	total: 8	correct: 8	acc: 100.0%
* class: 93 (watch)	total: 24	correct: 24	acc: 100.0%
* class: 94 (water_lilly)	total: 4	correct: 2	acc: 50.0%
* class: 95 (wheelchair)	total: 6	correct: 6	acc: 100.0%
* class: 96 (wild_cat)	total: 3	correct: 3	acc: 100.0%
* class: 97 (windsor_chair)	total: 6	correct: 5	acc: 83.3%
* class: 98 (wrench)	total: 4	correct: 2	acc: 50.0%
* class: 99 (yin_yang)	total: 6	correct: 6	acc: 100.0%
* average: 90.1%
Confusion matrix is saved to ./output/25-03-31-00-24-00/cmat.pt
epoch [28/50] batch [5/180] time 0.238 (0.344) data 0.000 (0.106) loss 0.1199 (0.0833) acc 90.6250 (96.8750) lr 1.0000e-05 eta 0:23:40
epoch [28/50] batch [10/180] time 0.237 (0.291) data 0.000 (0.053) loss 0.2733 (0.1745) acc 93.7500 (95.0000) lr 1.0000e-05 eta 0:20:00
epoch [28/50] batch [15/180] time 0.238 (0.273) data 0.000 (0.035) loss 0.0054 (0.1931) acc 100.0000 (95.2083) lr 1.0000e-05 eta 0:18:45
epoch [28/50] batch [20/180] time 0.237 (0.264) data 0.000 (0.027) loss 0.2813 (0.2242) acc 96.8750 (95.1562) lr 1.0000e-05 eta 0:18:07
epoch [28/50] batch [25/180] time 0.238 (0.259) data 0.000 (0.021) loss 0.1900 (0.2109) acc 93.7500 (95.0000) lr 1.0000e-05 eta 0:17:44
epoch [28/50] batch [30/180] time 0.237 (0.255) data 0.000 (0.018) loss 0.2560 (0.1954) acc 93.7500 (95.2083) lr 1.0000e-05 eta 0:17:28
epoch [28/50] batch [35/180] time 0.237 (0.253) data 0.000 (0.015) loss 0.2841 (0.1949) acc 90.6250 (95.0893) lr 1.0000e-05 eta 0:17:17
epoch [28/50] batch [40/180] time 0.237 (0.251) data 0.000 (0.013) loss 0.0816 (0.1888) acc 93.7500 (95.2344) lr 1.0000e-05 eta 0:17:08
epoch [28/50] batch [45/180] time 0.237 (0.249) data 0.000 (0.012) loss 0.2418 (0.1905) acc 93.7500 (95.2778) lr 1.0000e-05 eta 0:17:00
epoch [28/50] batch [50/180] time 0.238 (0.248) data 0.000 (0.011) loss 0.2299 (0.1905) acc 96.8750 (95.3125) lr 1.0000e-05 eta 0:16:54
epoch [28/50] batch [55/180] time 0.237 (0.247) data 0.000 (0.010) loss 0.3019 (0.1845) acc 90.6250 (95.2841) lr 1.0000e-05 eta 0:16:49
epoch [28/50] batch [60/180] time 0.238 (0.246) data 0.000 (0.009) loss 0.3209 (0.1780) acc 93.7500 (95.4167) lr 1.0000e-05 eta 0:16:45
epoch [28/50] batch [65/180] time 0.238 (0.246) data 0.000 (0.008) loss 0.0392 (0.1691) acc 96.8750 (95.5288) lr 1.0000e-05 eta 0:16:41
epoch [28/50] batch [70/180] time 0.237 (0.245) data 0.000 (0.008) loss 0.5533 (0.1682) acc 87.5000 (95.5804) lr 1.0000e-05 eta 0:16:37
epoch [28/50] batch [75/180] time 0.237 (0.245) data 0.000 (0.007) loss 0.1194 (0.1757) acc 93.7500 (95.4583) lr 1.0000e-05 eta 0:16:34
epoch [28/50] batch [80/180] time 0.238 (0.244) data 0.000 (0.007) loss 0.8267 (0.1831) acc 87.5000 (95.3906) lr 1.0000e-05 eta 0:16:31
epoch [28/50] batch [85/180] time 0.237 (0.244) data 0.000 (0.006) loss 0.0265 (0.1804) acc 100.0000 (95.4044) lr 1.0000e-05 eta 0:16:28
